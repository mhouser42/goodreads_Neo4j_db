{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning CSV\n",
    "\n",
    "This is my attempt at cleaning up the [Goodreads dataset I found on Kaggle](https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks). My eventual goal is to tranform the dataset and upload it to a Neo4j database. But there is a lot of work to be done before that. Let's get started!\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "the packages I'm including are fairly self explanatory, except for `FuzzyWuzzy` library, which i have not used before. `FuzzyWuzzy` is a Python library that provides tools for fuzzy string matching, allowing the user to compare strings that may have some differences or errors, such as typos or misspellings. It uses the Levenshtein Distance algorithm to calculate the difference between two strings, and returns a score between 0 and 100 that indicates how similar the strings are. I will be using this to clean up the `publisher` column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from fuzzywuzzy import fuzz, process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions\n",
    "\n",
    "These are the various functions I use throughout the notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def strip_spaces(x):\n",
    "    \"\"\"\n",
    "    removes all leading, trailing, and extra spaces from a string\n",
    "    \"\"\"\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        x = re.sub('\\s+', ' ', x)\n",
    "        return x\n",
    "    else:\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_isbn10(isbn):\n",
    "    \"\"\"\n",
    "    A function which determines if a given ISBN10 number is valid\n",
    "    \n",
    "    The rule for isbn's is that you multiply the first digit by 10, the second by 9, the third by 8th, ect.\n",
    "    The result of this calculation should be a number divisible by 11.\n",
    "    The final digit of an isbn may be an 'X'. This is to be interpreted as a 10 for purposes of calculation\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    \n",
    "    # intially checks if given isbn is the right length and characters are valid\n",
    "    if len(isbn) != 10:\n",
    "        return False\n",
    "    elif not isbn[0:8].isdigit():\n",
    "        return False\n",
    "    elif not isbn[-1].isdigit() or isbn[-1].lower() != 'x':\n",
    "        return False\n",
    "    \n",
    "    # iterates through isbn\n",
    "    for i in range(9):\n",
    "        result += result + int(isbn[i]) * (10 - i)\n",
    "    \n",
    "    # Adding last character\n",
    "    if isbn[9].lower() == 'x':\n",
    "        result += 10\n",
    "    else:\n",
    "        result += int(isbn[9])\n",
    "    \n",
    "    # determine validity of isbn\n",
    "    if result % 11 == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_all_isbn(df):\n",
    "    valid_count = 0\n",
    "    invalid_count = 0\n",
    "\n",
    "    for isbn in df['isbn_10']:\n",
    "        if validate_isbn10(isbn):\n",
    "            valid_count += 1\n",
    "        else:\n",
    "            invalid_count += 1\n",
    "\n",
    "    print(\"Valid ISBN count:\", valid_count)\n",
    "    print(\"Invalid ISBN count:\", invalid_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def standardize_name(name, default_names, threshold=65):\n",
    "    \"\"\"\n",
    "    compares a name to a list,\n",
    "    if the name is similar enough it returns the best match,\n",
    "    otherwise it keeps the name.\n",
    "    \"\"\"\n",
    "    best_match, score = process.extractOne(name.lower(), default_names)\n",
    "    if score >= threshold:\n",
    "        return best_match\n",
    "    else:\n",
    "        return name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data\n",
    "\n",
    "Intial attempt to load data fails."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('data/books_original_BROKEN.csv')\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The issue in the authors column. Some of the authors names have split into the next cell to the right, and consequentially pushed everything else over as well. In order to fix this, I have to manually go into excel and fix line 3350. There are other rows with this issue, but for whatever reason the others don't prevent parsing of the dataframe. I create a copy of `books.csv` called `books_dirty.csv` to maintain the orginial dataset. The remaining work will be preformed on this copy. \n",
    "\n",
    "Additionally, when loading this dataframe I didn't change the encoding. So foreign characters were not appearing properly. Discovered proper encoding `utf-8-sig`\n",
    "\n",
    "**Additionally ADDITIONALLY, I had been working for quite a while transforming the data before realizing that the isbn13 was not properly loading. The last six digits of each value was being replaced with zeros. I hunted around online and apparently I had to change it to *zipcodes* in excel for it to properly save the data. I don't know why this worked, and I'm not looking into it further.**\n",
    "\n",
    "**ADDITIONALLY ADDITIONALLY ADDITIONALLY** further investigation of `isbn` shows that when I intially edited `books.csv`, by opening it in excel I altered a lot of the data. As a result of this, ISBN's that began with a `0` where truncated to exclude the leading zero. After opening the file in notepad and making the changes manually, many of these issues were fixed. So...I have now saved three seperate .csv's. `book_original_BROKEN`, `books_dirty.csv`, and `books_dirty_manual_fix.csv`.\n",
    "\n",
    "### It turns out the real dirty data is the ones you make along the way."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/books_dirty.csv', dtype={'isbn13':str}, encoding='utf-8-sig') # Success!\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning\n",
    "## Columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So there is this pesky extra column. Another issue created by things being pushed over is the datatype of columns that should be `int64` have been converted to string objects. I create a mask to see exactly which rows are creating the problem.\n",
    "\n",
    "**ADDENDUM** after solving this problem manually in notepad, this code is no longer relevant. Keeping for posterity!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    mask = df['Unnamed: 12'].notnull()\n",
    "    column_12_df = df[mask]\n",
    "    print(column_12_df['Unnamed: 12'])\n",
    "    print(df['average_rating'].unique())\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since some of the authors are now in the `average_rating` column, I find all the places where this a value that isn't an `int`. I then append these values to the `authors` column, shift everything over and then then delete the `Unnamed: 12` column.\n",
    "\n",
    "**Again this is no longer an issue, but posterity!**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a boolean mask for non-numeric values in the 'average_rating' column\n",
    "error_mask = pd.to_numeric(df['average_rating'], errors='coerce').isnull()\n",
    "\n",
    "# Concatenate the 'authors' and 'average_rating' columns where there is an error\n",
    "df.loc[error_mask, 'authors'] = df.loc[error_mask, 'authors'] + ' ' + df.loc[mask, 'average_rating']\n",
    "\n",
    "# Shift all values to the right of the 'average_rating' column one cell to the left where there was an error\n",
    "df.loc[error_mask, 'average_rating':'publisher'] = df.loc[error_mask, 'isbn':'Unnamed: 12'].values\n",
    "\n",
    "#delete the Unnamed: 12 column\n",
    "df = df.drop(columns=['Unnamed: 12'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df['average_rating'].unique())\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I now go through the columns and alter the datatypes. `average_rating` should be a float, `num_pages`, `ratings_count`, and `text_reviews_count` should all be integers, and the `publication_date` should be a date. I also clean up the titles of columns. `num_pages` obviously has some extra spaces, so I strip leading and trialing spaces. To be safe, I do this to all column titles."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cleaning column titles\n",
    "df.columns = [strip_spaces(col) for col in df.columns]\n",
    "df.info()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# transform column datatypes\n",
    "df = df.astype({'average_rating': float, 'num_pages': int, 'ratings_count': int, 'text_reviews_count': int})\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "no problems with the above transformations. Translating `publication_date` to datetime proves problematic."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    df['publication_date'] = pd.to_datetime(df['publication_date'], format='%m/%d/%Y')\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Force converstion, transforming invalid dates to `NaT`. Find specific rows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['publication_date'] = pd.to_datetime(df['publication_date'], format='%m/%d/%Y', errors='coerce')\n",
    "df[df['publication_date'].isna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the data in the excel spreadsheet, these two have publications on the 31st of months that don't have 31 days! Did a little research and found correct publication dates for both. double check they are correct datatype."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.loc[df['isbn'] == '553575104', 'publication_date'] = '10/31/2000'\n",
    "df.loc[df['isbn'] == '2070323285', 'publication_date'] = '01/01/1975'\n",
    "print(type(df.loc[8180, 'publication_date']))\n",
    "print(type(df.loc[11098, 'publication_date']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that all the existing columns are the correct datatype, I want to change the some of the titles. I also now strip all leading, trailing, and inbetween extra spaces in the dataset (before I forget)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.rename(columns={'bookID': 'book_id', 'isbn': 'isbn_10', 'isbn13': 'isbn_13'})\n",
    "df = df.applymap(strip_spaces)\n",
    "df.info()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ISBNs\n",
    "\n",
    "Last semester when I was looking at the `isbn` and `isbn13` columns I felt they were largely redundant. I am now throughly convinced that they in fact AREN'T redudant. Which actually turns out to be larger issue. I start by checking the lengths of the values. `isbn` numbers should be 10 characters long, and `isbn13` should be 13 characters long."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['isbn_10'].str.len().value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['isbn_13'].str.len().value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oh no! So there are obviously some issues, more so in the `isbn` column than the `isbn13` column. The first thing I'm going to check is how many of the ISBN's are valid. An ISBN10 is valid when the sum of multipling the first digit by 10, the second by 9, the third by 8th, ect. results in a number divisble by 11. Additionally, The final digit of an isbn may be an 'X'. This is to be interpreted as a 10 for purposes of calculation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_isbn10(isbn):\n",
    "    \"\"\"\n",
    "    A function which determines if a given ISBN10 number is valid\n",
    "    \n",
    "    The rule for isbn's is that you multiply the first digit by 10, the second by 9, the third by 8th, ect.\n",
    "    The result of this calculation should be a number divisible by 11.\n",
    "    The final digit of an isbn may be an 'X'. This is to be interpreted as a 10 for purposes of calculation\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    \n",
    "    # intially checks if given isbn is the right length and characters are valid\n",
    "    if len(isbn) != 10:\n",
    "        return False\n",
    "    elif not isbn[0:8].isdigit():\n",
    "        return False\n",
    "    elif not isbn[-1].isdigit() and isbn[-1].lower() != 'x':\n",
    "        return False\n",
    "    \n",
    "    # iterates through isbn\n",
    "    for i in range(9):\n",
    "        result += int(isbn[i]) * (10 - i)\n",
    "    \n",
    "    # Adding last character\n",
    "    if isbn[9].lower() == 'x':\n",
    "        result += 10\n",
    "    else:\n",
    "        result += int(isbn[9])\n",
    "    \n",
    "    # determine validity of isbn\n",
    "    if result % 11 == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_all_isbn(df):\n",
    "    valid_count = 0\n",
    "    invalid_count = 0\n",
    "\n",
    "    for isbn in df['isbn_10']:\n",
    "        if validate_isbn10(isbn):\n",
    "            valid_count += 1\n",
    "        else:\n",
    "            invalid_count += 1\n",
    "\n",
    "    print(\"Valid ISBN count:\", valid_count)\n",
    "    print(\"Invalid ISBN count:\", invalid_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate_all_isbn(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So it looks like the majority of isbns that are the correct length are valid. let's take a look at those that are only a digit short. I have a hunch I want to check out. I'm thinking that it's possible that leading zeros were dropped from the orginal dataset during encoding."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "short_isbn = df[df['isbn_10'].str.len() == 9]['isbn_10']\n",
    "df_short_isbn = short_isbn.to_frame()\n",
    "df_short_isbn['isbn_10'] = '0' + df_short_isbn['isbn_10'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "and now check with the validity function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate_all_isbn(df_short_isbn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Success!!! I now implement this change in the orginal dataframe. And check once more."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.loc[df['isbn_10'].str.len() == 9, 'isbn_10'] = '0' + df.loc[df['isbn_10'].str.len() == 9, 'isbn_10']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate_all_isbn(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ADDENDUM:\n",
    "\n",
    "so again, after the manual fix, this issue isn't a problem. When we load the manual fix file into the dataframe we get very different results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manual_fix_df = pd.read_csv('data/books_dirty_manual_fix.csv', dtype={'isbn13':str}, encoding='utf-8-sig')\n",
    "\n",
    "manual_fix_df.columns = [strip_spaces(col) for col in manual_fix_df.columns]\n",
    "manual_fix_df = manual_fix_df.astype({'average_rating': float, 'num_pages': int, 'ratings_count': int, 'text_reviews_count': int})\n",
    "manual_fix_df = manual_fix_df.rename(columns={'bookID': 'book_id', 'isbn': 'isbn_10', 'isbn13': 'isbn_13'})\n",
    "manual_fix_df = manual_fix_df.applymap(strip_spaces)\n",
    "\n",
    "manual_fix_df['publication_date'] = pd.to_datetime(df['publication_date'], format='%m/%d/%Y', errors='coerce')\n",
    "manual_fix_df.loc[df['isbn_10'] == '553575104', 'publication_date'] = '10/31/2000'\n",
    "manual_fix_df.loc[df['isbn_10'] == '2070323285', 'publication_date'] = '01/01/1975'\n",
    "\n",
    "manual_fix_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manual_fix_df['isbn_10'].str.len().value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manual_fix_df['isbn_13'].str.len().value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate_all_isbn(manual_fix_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I have learned a valuable lesson. That lesson being: **I both don't understand and deeply hate Excel.** With this lesson in mind, I will be going forward with the manual fix dataframe for the remainder of my editing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = manual_fix_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inserting audio column\n",
    "\n",
    "It appears that there is no distinction made between text and audiobooks. This creates confusing data where \"books\" will single digit number of pages. I find distinct publishers and create two lists, one for regular books and one for audiobooks. Any publisher with \"audio\", \"tape\", \"media\", and \"listen\" in the name or that have 15 or less pages is added to the audio_publishers list."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "publishers = df['publisher'].unique()\n",
    "audio_publishers = df[df['publisher'].str.contains('audio|tape|media|listen|caedmon', case=False) | (df['num_pages'] <= 15)]['publisher'].unique()\n",
    "print_publishers = list(set(publishers) - set(audio_publishers))\n",
    "\n",
    "print('list of print publishers:')\n",
    "for pub in sorted(print_publishers):\n",
    "    print('\\t' + pub)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('list of audio publishers:')\n",
    "for pub in sorted(audio_publishers):\n",
    "    print('\\t' + pub)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a lot of duplicates in both! This is something I'll need to fix, but for now I will use the lists to insert a new column `audio_book` which contains a boolean value denoting if said book is an audiofile, then my dataframe so that this column appears after the language_code."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "audio_mask = df[\"publisher\"].isin(audio_publishers)\n",
    "df['audio_book'] = audio_mask\n",
    "column_order= ['book_id',\n",
    "               'title',\n",
    "               'authors',\n",
    "               'isbn_10',\n",
    "               'isbn_13',\n",
    "               'language_code',\n",
    "               'audio_book',\n",
    "               'num_pages',\n",
    "               'ratings_count',\n",
    "               'average_rating',\n",
    "               'text_reviews_count',\n",
    "               'publication_date',\n",
    "               'publisher']\n",
    "df = df[column_order]\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Publishers Cleanup\n",
    "\n",
    "So there were a lot of duplicate values in the publisher column. Now admittedly, there are a lot of different imprints of publishers, but I think my eventual calculations in Neo4j will benefit from the simplification. I will be using the fuzzywuzzy package to help clean up some of the names.  and also `str.title()` method to normalize the names a little more."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of Publishers: {len(df[\"publisher\"].unique())}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def standardize_name(name, default_names, threshold=65):\n",
    "    \"\"\"compares a name to a list,\n",
    "    if the name is similar enough it returns the best match,\n",
    "    otherwise it keeps the name\"\"\"\n",
    "    best_match, score = process.extractOne(name.lower(), default_names)\n",
    "    if score >= threshold:\n",
    "        return best_match\n",
    "    else:\n",
    "        return name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['publisher'] = df['publisher'].str.title()\n",
    "\n",
    "publisher_counts = df['publisher'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "default_publishers = list(publisher_counts[publisher_counts >= 25].index)\n",
    "\n",
    "df['publisher'] = df['publisher'].apply(standardize_name, args=(default_publishers,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of Publishers: {len(df[\"publisher\"].unique())}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted(df['publisher'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So everything is looking good. We've chopped the list of publishers to a little over half of what it used to be. I'm a little tired of trying to automate everything (fuzzywuzzy was pain to figure out) so I decide to just roll up my sleeves and pare down the list more manually. I will mostly be using regex with a custom function to remove extra things I don't want, and the `df.loc` and `str.contains` methods to normalize larger publishers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_regex_pattern(regex, column='publisher'):\n",
    "    pattern = re.compile(regex)\n",
    "    df[column] = df[column].str.replace(pattern, '')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove anything inside parenthesis\n",
    "remove_regex_pattern(r'\\s*\\([^)]*\\)')\n",
    "\n",
    "# Remove Ltd\n",
    "remove_regex_pattern(r'\\bLtd\\.?\\b')\n",
    "\n",
    "# Remove Inc and Inc.\n",
    "remove_regex_pattern(r'\\bInc\\.?\\b')\n",
    "\n",
    "#Remove Publisher and Publishers\n",
    "remove_regex_pattern(r'.Publisher(s)?\\b')\n",
    "\n",
    "# Remove wierd space plus period\n",
    "remove_regex_pattern(r'\\s\\.')\n",
    "\n",
    "# Remove 'Tb'\n",
    "remove_regex_pattern(r'\\sTb\\.?')\n",
    "\n",
    "# Remove Verlag\n",
    "remove_regex_pattern(r'\\sVerlag')\n",
    "\n",
    "df['publisher'] = df['publisher'].str.replace(r'\\s+And\\s+', ' & ')\n",
    "df['publisher'] = df['publisher'].str.replace(r'Pubns', '')\n",
    "\n",
    "# Change Bbc to BBC because it was bothering me\n",
    "df['publisher'] = df['publisher'].str.replace(r'Bbc', 'BBC')\n",
    "\n",
    "# Melt Bloomsbury companies into single publisher\n",
    "df.loc[df['publisher'].str.contains('Bloomsbury'), 'publisher'] = 'Bloomsbury Publishing'\n",
    "\n",
    "# Same with Gallimard\n",
    "df.loc[df['publisher'].str.contains('Gallimard'), 'publisher'] = 'Gallimard'\n",
    "\n",
    "# Hachette\n",
    "df.loc[df['publisher'].str.contains('Hachette'), 'publisher'] = 'Hachette'\n",
    "\n",
    "# Harlequin\n",
    "df.loc[df['publisher'].str.contains('Harlequin'), 'publisher'] = 'Harlequin'\n",
    "\n",
    "# HarperCollins\n",
    "df.loc[df['publisher'].str.contains('Harper'), 'publisher'] = 'HarperCollins'\n",
    "\n",
    "# Headline\n",
    "df.loc[df['publisher'].str.contains('Headline'), 'publisher'] = 'Headline'\n",
    "\n",
    "# Kodansha\n",
    "df.loc[df['publisher'].str.contains('Kodansha'), 'publisher'] = 'Kodansha'\n",
    "\n",
    "# Macmillan\n",
    "df.loc[df['publisher'].str.contains('Macmillan'), 'publisher'] = 'Macmillan'\n",
    "\n",
    "# Macgraw-Hill\n",
    "df.loc[df['publisher'].str.contains('Mcgraw-Hill'), 'publisher'] = 'Mcgraw-Hill'\n",
    "\n",
    "# Penguin\n",
    "df.loc[df['publisher'].str.contains('Penguin'), 'publisher'] = 'Penguin'\n",
    "\n",
    "# Random House\n",
    "df.loc[df['publisher'].str.contains('Random House'), 'publisher'] = 'Random House'\n",
    "\n",
    "# Reclam\n",
    "df.loc[df['publisher'].str.contains('Reclam'), 'publisher'] = 'Reclam'\n",
    "\n",
    "# Silhouette\n",
    "df.loc[df['publisher'].str.contains('Silhouette'), 'publisher'] = 'Silhouette'\n",
    "\n",
    "# St. Martin's\n",
    "df.loc[df['publisher'].str.contains('St. Martin'), 'publisher'] = \"St. Martin's\"\n",
    "\n",
    "# Viking\n",
    "df.loc[df['publisher'].str.contains('Viking'), 'publisher'] = 'Viking'\n",
    "\n",
    "# Warner\n",
    "df.loc[df['publisher'].str.contains('Warner'), 'publisher'] = 'Warner Books'\n",
    "\n",
    "# Strip leading/trailing whitespaces I might have created\n",
    "df['publisher'] = df['publisher'].str.strip()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Number of Publishers: {len(df[\"publisher\"].unique())}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted(df['publisher'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, I go through the list and do the thing I was avoiding up till now, individually correcting/mapping publishers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "publisher_mapping = {\n",
    "    '18-Oct': 'Vintage',\n",
    "    'Chatto Windus': 'Chatto & Windus',\n",
    "    'Debols!Llo': 'Debolsillo',\n",
    "    'Douglas Mcintyre': 'Douglas & Mcintyre',\n",
    "    'Doubleday Canada': 'Doubleday Publishing',\n",
    "    'Doubleday': 'Doubleday Publishing',\n",
    "    'Dk': 'Dk Publishing',\n",
    "    'Dk Children': 'Dk Publishing',\n",
    "    'Emecé Editores': 'Emece Editores',\n",
    "    'Faber & Faber Limited': 'Faber & Faber',\n",
    "    'Faber Faber': 'Faber & Faber',\n",
    "    'Fawcett Coventry': 'Fawcett',\n",
    "    'Fawcett Crest': 'Fawcett',\n",
    "    'Fasa Corp.': 'Fasa Corporation',\n",
    "    'Five Star': 'Five Star Trade',\n",
    "    'Fourth Estate Paperbacks': 'Fourth Estate',\n",
    "    'Hill & Wang Publ.': 'Hill & Wang',\n",
    "    'Hodder & Stoughton Educational Division': 'Hodder & Stoughton',\n",
    "    'Inner Traditions International': 'Inner Traditions',\n",
    "    'Insel Frankfurt': 'Insel',\n",
    "    'John Wiley': 'John Wiley & Sons',\n",
    "    'Limelight Editions': 'Limelight',\n",
    "    'Liveright': 'Liveright Publishing Corp.',\n",
    "    'Nal': 'New American Library',\n",
    "    'Nal Jam': 'New American Library',\n",
    "    'Nal Trade': 'New American Library',\n",
    "    'National Geographic Society': 'National Geographic',\n",
    "    'Plaza & Janes Editores Sa': 'Plaza & Janés',\n",
    "    'Plaza & Janés Mexico': 'Plaza & Janés',\n",
    "    'Plaza Y Janés': 'Plaza & Janés',\n",
    "    'Prentice Hall Ptr': 'Prentice Hall',\n",
    "    'Roc Hardcover': 'Roc',\n",
    "    'Roc Trade': 'Roc',\n",
    "    'Rowohlt Taschenbuch Gmbh': 'Rowohlt',\n",
    "    'Schirmer Mosel': 'Schirmer/Mosel',\n",
    "    'Simon Schuster': 'Simon & Schuster',\n",
    "    'Thames Hudson': 'Thames & Hudson',\n",
    "    'Ullstein Buchverlage Gmbh & Co. Kg / Ullstein Tas': 'Ullstein',\n",
    "    'Virago Uk': 'Virago',\n",
    "    'Vision Forum': 'Vision',\n",
    "    'W. W. Norton Company': 'W. W. Norton & Company',\n",
    "    'William Morrow Paperbacks': 'William Morrow',\n",
    "    '小学館 [ShōGakukan]': '小学館'\n",
    "}\n",
    "\n",
    "df['publisher'] = df['publisher'].replace(publisher_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df['publisher'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)\n",
    "df['book_id'] = df.index + 1\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Author and Publication Tables\n",
    "\n",
    "Now that I've cleaned up the publishers, I'm ready to create seperate tables. I will be making both an `author` and a `publisher` table. The `author` table is necessary in order to properly extract names from the `authors` column of the our original dataset, without creating a lot of extra null values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split authors column and create a new dataframe\n",
    "authors_df = df[['book_id', 'authors']].set_index('book_id').stack().str.split('/', expand=True).stack().reset_index(level=1, drop=True).reset_index(name='author_name')\n",
    "\n",
    "# Create author_id column\n",
    "unique_authors = sorted(authors_df['author_name'].unique())\n",
    "author_id = range(1, len(unique_authors) + 1)\n",
    "authors_dict = {'author_name': unique_authors, 'author_id': author_id}\n",
    "authors_id_df = pd.DataFrame(authors_dict)\n",
    "\n",
    "authors_df = pd.merge(authors_df, authors_id_df, on='author_name')\n",
    "\n",
    "# Reorder columns and rows\n",
    "authors_df = authors_df[['author_id', 'author_name', 'book_id']]\n",
    "authors_df = authors_df.sort_values(by='author_id')\n",
    "authors_df = authors_df.reset_index(drop=True)\n",
    "authors_df.head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Looks good! Now for the publishers. The `publication` table needs to be created in order for me to more easily implement my upload to neo4j. It will be pretty straight forward, with `publisher_id`, `publisher_name`, `publication_date`, and `book_id` foreign key. The only thing that really needs to be created is the `publisher_id`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create publisher ids\n",
    "unique_publishers = sorted(df['publisher'].unique())\n",
    "publisher_id = range(1, len(unique_publishers) + 1)\n",
    "publisher_dict = {'publisher_id': publisher_id, 'publisher': unique_publishers}\n",
    "unique_publisher_df = pd.DataFrame(publisher_dict)\n",
    "\n",
    "# create new table\n",
    "publisher_df = df[['publisher', 'publication_date', 'book_id']]\n",
    "publisher_df = pd.merge(publisher_df, unique_publisher_df, on='publisher')\n",
    "\n",
    "# resturcture table\n",
    "publisher_df = publisher_df[['publisher_id', 'publisher', 'publication_date', 'book_id']]\n",
    "publisher_df = publisher_df.sort_values(by='publisher_id')\n",
    "publisher_df = publisher_df.reset_index(drop=True)\n",
    "publisher_df = publisher_df.rename(columns={'publisher': 'publisher_name'})\n",
    "publisher_df.head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapping up!\n",
    "\n",
    "The final steps are removing redundant columns from my original dataframe and using `.to_csv` to export all my new tables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(['authors', 'publication_date', 'publisher'], axis=1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('data/books_cleaned.csv', index=False)\n",
    "authors_df.to_csv('data/authors.csv')\n",
    "publisher_df.to_csv('data/publishers.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# See neo4j_upload.ipynb for next steps!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "98ef2db0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['publisher'] = df['publisher'].str.title()\n",
    "\n",
    "publisher_counts = df['publisher'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "default_publishers = list(publisher_counts[publisher_counts >= 25].index)\n",
    "\n",
    "df['publisher'] = df['publisher'].apply(standardize_name, args=(default_publishers,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "11270c7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Publishers: 872\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Publishers: {len(df[\"publisher\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "daef3c19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10/18',\n",
       " '1St Book Library',\n",
       " 'Aa World Services',\n",
       " 'Abacus',\n",
       " 'Abstract Studio',\n",
       " 'Academy Chicago Publishers',\n",
       " 'Ace',\n",
       " 'Actes Sud',\n",
       " 'Addison Wesley',\n",
       " 'Addison-Wesley Professional',\n",
       " 'Adv Manga',\n",
       " 'Aegypan',\n",
       " 'Aha! Process',\n",
       " 'Ait Planet Lar',\n",
       " 'Aladdin',\n",
       " 'Albert Whitman Company',\n",
       " 'Albin Michel',\n",
       " 'Alcoholics Anonymous World Services Inc',\n",
       " 'Alderac Entertainment Group',\n",
       " 'Alderac Entertainment Group (Aeg)',\n",
       " 'Alfabeta Bokförlag',\n",
       " 'Alfaguara',\n",
       " 'Alfaguara Infantil',\n",
       " 'Alfred A. Knopf',\n",
       " 'Alianza Editorial',\n",
       " 'Allen & Ulwin',\n",
       " 'Allen Lane',\n",
       " 'Allworth',\n",
       " 'Alpha',\n",
       " 'Amadeus',\n",
       " 'Amereon Limited',\n",
       " \"America'S Test Kitchen\",\n",
       " 'American Diabetes Association',\n",
       " 'Amistad',\n",
       " 'Amr/Advanced Management Reports',\n",
       " 'Anagrama',\n",
       " 'Anchor',\n",
       " 'Anchor Books',\n",
       " 'Andrews And Mcmeel',\n",
       " 'Apple',\n",
       " 'Archaia',\n",
       " 'Arden Shakespeare',\n",
       " 'Aris & Phillips',\n",
       " 'Aris And Phillips',\n",
       " 'Arkana',\n",
       " 'Arrow',\n",
       " 'Arthur A. Levine',\n",
       " 'Artisan',\n",
       " 'Aspect',\n",
       " 'Atheneum',\n",
       " 'Audio Literature',\n",
       " 'Audio Partners',\n",
       " 'Audio Renaissance',\n",
       " 'Audiogo',\n",
       " 'Audiotext',\n",
       " 'Augsburg Fortress Publishing',\n",
       " 'Aurum',\n",
       " 'Authorhouse',\n",
       " 'Avon',\n",
       " 'Babel',\n",
       " 'Back Bay Books',\n",
       " 'Backinprint.Com',\n",
       " 'Ballantine Books',\n",
       " 'Bantam',\n",
       " 'Bantam Books',\n",
       " 'Barnes Noble Classics',\n",
       " 'Barrington Stoke',\n",
       " 'Basic Books',\n",
       " 'Bastei Lübbe',\n",
       " 'Batsford',\n",
       " 'Bbc Audiobooks',\n",
       " 'Bbc Audiobooks America',\n",
       " 'Bbc Audiobooks Ltd',\n",
       " 'Bbc Physical Audio',\n",
       " 'Bbc Worldwide',\n",
       " 'Bcp/Duckworth Publishing',\n",
       " 'Be Beautiful',\n",
       " 'Beltz Und Gelberg',\n",
       " 'Benjamin Cummings',\n",
       " 'Benziger',\n",
       " 'Berkley',\n",
       " 'Berkley Books',\n",
       " 'Berlitz Kids',\n",
       " 'Berrett-Koehler Publishers',\n",
       " 'Bertrand',\n",
       " 'Between The Lines Productions',\n",
       " 'Bibliolife',\n",
       " 'Big Finish',\n",
       " 'Birlinn',\n",
       " 'Black Dog & Leventhal',\n",
       " 'Black Dog & Leventhal Publishers',\n",
       " 'Black Swan',\n",
       " 'Blackstone Publishing',\n",
       " 'Blanvalet Taschenbuch',\n",
       " 'Blanvalet Taschenbuch Verlag',\n",
       " 'Blanvalet Verlag Gmbh',\n",
       " 'Blood Moon Productions',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury (Nyc)',\n",
       " 'Bloomsbury / Continuum',\n",
       " 'Bloomsbury Academic',\n",
       " 'Bloomsbury Arden Shakespeare',\n",
       " 'Bloomsbury Methuen Drama',\n",
       " 'Bloomsbury Paperbacks',\n",
       " 'Bloomsbury Publishing',\n",
       " 'Bloomsbury Publishing Plc',\n",
       " 'Bloomsbury Uk',\n",
       " 'Blu',\n",
       " 'Bolchazy-Carducci Publishers',\n",
       " 'Book Of The Month Club',\n",
       " 'Bookclub-In-A-Box',\n",
       " 'Booksales',\n",
       " 'Bradygames',\n",
       " 'Bragelonne',\n",
       " 'Brava',\n",
       " 'Brill/Rodopi',\n",
       " 'Brilliance Audio',\n",
       " 'British Academy',\n",
       " 'British Film Institute',\n",
       " 'British Library',\n",
       " 'Broadway Books',\n",
       " 'Brown Son & Ferguson Ltd.',\n",
       " 'Bruno Gmünder',\n",
       " 'Bryn Mawr Commentaries',\n",
       " 'Btb',\n",
       " 'Bulfinch',\n",
       " 'Bureau Of Public Secrets',\n",
       " 'Business Plus',\n",
       " 'Byblos',\n",
       " 'C. Bange',\n",
       " 'Caedmon',\n",
       " 'Cambridge University Press',\n",
       " 'Candlewick',\n",
       " 'Cardoza',\n",
       " 'Carl Hanser',\n",
       " 'Carlsen',\n",
       " 'Carole Marsh Mysteries',\n",
       " 'Cartago',\n",
       " 'Cartwheel',\n",
       " 'Casa Creacion',\n",
       " 'Catholic Book Publishing',\n",
       " 'Celestial Arts',\n",
       " 'Center Point',\n",
       " 'Century',\n",
       " 'Chaosium',\n",
       " 'Charlesbridge',\n",
       " 'Charnwood',\n",
       " 'Chatto & Windus',\n",
       " 'Chatto And Windus',\n",
       " 'Chatto Windus',\n",
       " 'Cherry Lane Music Company',\n",
       " \"Child'S Play International\",\n",
       " 'Churchill Livingstone',\n",
       " 'Cisne',\n",
       " 'City Lights',\n",
       " 'Claassen Verlag',\n",
       " 'Clarkson Potter',\n",
       " 'Clarkson Potter Publishers',\n",
       " 'Clarkson Potter/Publishers',\n",
       " 'Cliffs Notes',\n",
       " 'Cmx',\n",
       " 'Collins Design',\n",
       " 'Collins Reference',\n",
       " 'Columbia Pictures Pubns',\n",
       " 'Comicsone Corporation',\n",
       " 'Companhia Das Letras',\n",
       " 'Contemporary French Fiction',\n",
       " 'Continuum',\n",
       " \"Cook'S Illustrated\",\n",
       " 'Cooper Square Publishers',\n",
       " 'Corgi',\n",
       " 'Corgi Childrens',\n",
       " 'Coronet',\n",
       " 'Counterpoint',\n",
       " 'Counterpoint Llc',\n",
       " 'Course Technology',\n",
       " 'Crescent',\n",
       " 'Critica (Grijalbo Mondadori)',\n",
       " 'Crossroad',\n",
       " 'Crown Business',\n",
       " 'Crown Forum',\n",
       " 'Crystal Clarity Publishers',\n",
       " 'Cybereditions Corp',\n",
       " 'Cátedra',\n",
       " 'Dabel Brothers Productions',\n",
       " 'Dabel Brothers Publishing',\n",
       " 'Daimon Verlag',\n",
       " 'Dark Horse',\n",
       " 'Dark Horse Manga',\n",
       " 'Darton Longman & Todd',\n",
       " 'David C Cook',\n",
       " 'David C. Cook',\n",
       " 'David R. Godine',\n",
       " 'David R. Godine Publisher',\n",
       " 'Daw',\n",
       " 'Dc Comics',\n",
       " 'De Boekerij',\n",
       " 'Debolsillo',\n",
       " 'Dedalus',\n",
       " 'Dedalus Limited',\n",
       " 'Del Rey',\n",
       " 'Del Rey Books',\n",
       " 'Dell',\n",
       " 'Delta',\n",
       " 'Deodand',\n",
       " 'Destino Ediciones',\n",
       " 'Destiny Image Incorporated',\n",
       " 'Deutscher Taschenbuch Verlag',\n",
       " \"Devil'S Due Publishing\",\n",
       " 'Dhv Der Hörverlag',\n",
       " 'Diana Tb',\n",
       " 'Digireads.Com',\n",
       " 'Diogenes',\n",
       " 'Diogenes Verlag',\n",
       " 'Disney Editions',\n",
       " 'Disney Enterprises',\n",
       " 'Disney-Hyperion',\n",
       " 'Dk',\n",
       " 'Dk Children',\n",
       " 'Dk Publishing (Dorling Kindersley)',\n",
       " 'Dodd Mead; 1St Edition (September 1976)',\n",
       " 'Dorling Kindersley Children',\n",
       " 'Doubleday',\n",
       " 'Doubleday Canada',\n",
       " 'Doubleday Publishing (Ny)',\n",
       " 'Douglas & Mcintyre',\n",
       " 'Douglas Mcintyre',\n",
       " 'Dover Publications',\n",
       " 'Dr. Master Productions Inc.',\n",
       " 'Dramatists Play Service',\n",
       " 'Dramatists Play Service Inc.',\n",
       " 'Drawn And Quarterly',\n",
       " 'Droemer Knaur',\n",
       " 'Dtv',\n",
       " 'Dundurn',\n",
       " 'Dutton',\n",
       " 'Dutton Adult',\n",
       " 'Dutton Juvenile',\n",
       " 'Ediciones B',\n",
       " 'Ediciones Glénat España',\n",
       " 'Ediciones Urano',\n",
       " 'Edimat Libros',\n",
       " 'Editions 10/18',\n",
       " 'Editions Du Rocher',\n",
       " 'Editions Gallimard',\n",
       " 'Editorial Diana',\n",
       " 'Editorial Juventud',\n",
       " 'Editorial Presença',\n",
       " 'Editorial Rm',\n",
       " 'Element',\n",
       " 'Ember',\n",
       " 'Emece Editores',\n",
       " 'Emecé Editores',\n",
       " 'Eminent Lives',\n",
       " 'Eos',\n",
       " 'Eros Comix',\n",
       " 'Europa Editions',\n",
       " 'Evans Brothers',\n",
       " \"Everyman'S Library\",\n",
       " 'Exact Change',\n",
       " 'F. Meiner',\n",
       " 'Faber & Faber',\n",
       " 'Faber & Faber Limited',\n",
       " 'Faber & Faber Ltd.',\n",
       " 'Faber Faber',\n",
       " 'Faithwords',\n",
       " 'Fanfare',\n",
       " 'Fantagraphics',\n",
       " 'Fantasy Flight Games',\n",
       " 'Farrar Straus And Giroux',\n",
       " 'Fasa Corp.',\n",
       " 'Fasa Corporation',\n",
       " 'Fawcett',\n",
       " 'Fawcett Coventry',\n",
       " 'Fawcett Crest',\n",
       " 'Feiwel & Friends',\n",
       " 'Felony & Mayhem',\n",
       " 'Festival',\n",
       " 'Findakly',\n",
       " 'Firebird',\n",
       " 'Fireside',\n",
       " 'Fischer (Tb.)',\n",
       " 'Fischer Taschenbuch Verlag',\n",
       " 'Fischer Tb',\n",
       " 'Five Star (Me)',\n",
       " 'Five Star Trade',\n",
       " 'Flamingo',\n",
       " 'Focus',\n",
       " 'Folio',\n",
       " 'Folio Histoire',\n",
       " 'Fonolibro',\n",
       " 'Fontana',\n",
       " 'Forge',\n",
       " 'Fount',\n",
       " 'Four Ninety-Eight Productions',\n",
       " 'Fourth Estate',\n",
       " 'Fourth Estate (Gb)',\n",
       " 'Fourth Estate Ltd',\n",
       " 'Fourth Estate Paperbacks',\n",
       " 'Franklin Watts',\n",
       " 'Free Press',\n",
       " 'French & European',\n",
       " 'French & European Pubns',\n",
       " 'Futura',\n",
       " \"G.P. Putnam'S Sons\",\n",
       " 'Gale Cengage',\n",
       " 'Gallimard',\n",
       " 'Gallimard Education',\n",
       " 'Gallimard Jeunesse',\n",
       " 'Gallopade International',\n",
       " 'Gamble Guides',\n",
       " 'Games Workshop',\n",
       " 'Games Workshop(Uk)',\n",
       " 'Geddes & Grosset',\n",
       " 'George Braziller',\n",
       " 'Gibbs Smith',\n",
       " 'Gibbs Smith Publishers',\n",
       " 'Globe',\n",
       " 'Glénat',\n",
       " 'Gold Eagle',\n",
       " 'Golden/Disney',\n",
       " 'Goldmann',\n",
       " 'Goldmann Verlag',\n",
       " 'Gollancz',\n",
       " 'Gotham',\n",
       " 'Grafton',\n",
       " 'Gramedia Pustaka Utama',\n",
       " 'Gramercy',\n",
       " 'Grand Central Publishing',\n",
       " 'Granta Uk',\n",
       " 'Grasset',\n",
       " 'Green Integer',\n",
       " 'Greenwood',\n",
       " 'Grijalbo',\n",
       " 'Grijalbo Mondadori Sa',\n",
       " 'Grosset & Dunlap',\n",
       " 'Grove Press',\n",
       " 'Grove Weidenfeld',\n",
       " 'Grupo Océano',\n",
       " 'Hachette Audio',\n",
       " \"Hachette Children'S\",\n",
       " 'Hachette Jeunesse',\n",
       " 'Hachette Littérature',\n",
       " 'Hackett Publishing Company Inc.',\n",
       " 'Hakusen Sha',\n",
       " 'Hal Leonard Pub Corp',\n",
       " 'Hamish Hamilton',\n",
       " 'Hamish Hamilton Ltd',\n",
       " 'Harcourt Brace Jovanovich',\n",
       " 'Harcourt Brace Jovanovich (Ny)',\n",
       " 'Harcourt Brace Jovanovich/Harvest',\n",
       " 'Harcourt Inc.(Harvest Book)',\n",
       " 'Hard Crime Case',\n",
       " 'Harlequin',\n",
       " 'Harlequin American Romance',\n",
       " 'Harlequin Anthologies',\n",
       " 'Harlequin Blaze',\n",
       " 'Harlequin Historical',\n",
       " 'Harlequin Presents',\n",
       " \"Harlequin Readers' Choice\",\n",
       " 'Harlequin Romance',\n",
       " 'Harlequin Special Releases',\n",
       " 'Harlequin Superromance',\n",
       " 'Harlequin Temptation',\n",
       " 'Harmony',\n",
       " 'Harper',\n",
       " 'Harper Perennial',\n",
       " 'Harper Perennial Modern Classics',\n",
       " 'Harpercollins',\n",
       " 'Harpercollins Publishers',\n",
       " 'Harperone',\n",
       " 'Harpertorch',\n",
       " 'Harry N. Abrams',\n",
       " 'Harvard University Press',\n",
       " 'Harvest / Harcourt',\n",
       " 'Hci',\n",
       " 'Headline',\n",
       " 'Headline Book Pub Ltd',\n",
       " 'Headline Book Publishing',\n",
       " 'Headline Feature',\n",
       " 'Headline Review',\n",
       " 'Health Communications',\n",
       " 'Health Communications Inc',\n",
       " 'Hearst Communications',\n",
       " 'Heinemann',\n",
       " 'Heinemann Drama',\n",
       " 'Heinemann-Octopus',\n",
       " 'Heinle',\n",
       " 'Henry Holt',\n",
       " 'Henry Holt And Co.',\n",
       " 'Henry Holt And Co. (Byr)',\n",
       " 'Heyne',\n",
       " 'Highbridge Audio',\n",
       " 'Hill & Wang',\n",
       " 'Hill & Wang Publ. (Ny)',\n",
       " 'Hiperión',\n",
       " 'Hj Kramer',\n",
       " 'Hmh Books For Young Readers',\n",
       " 'Hodder',\n",
       " 'Hodder & Stoughton',\n",
       " 'Hodder & Stoughton Educational Division',\n",
       " 'Hodder & Stoughton Ltd',\n",
       " 'Hodder And Stoughton',\n",
       " 'Hodder Mobius',\n",
       " 'Hodder Wayland',\n",
       " 'Holt Mcdougal',\n",
       " 'Holt Rinehart And Winston Inc.',\n",
       " 'Houghton Mifflin Harcourt',\n",
       " 'Hqn',\n",
       " 'Hungry Minds',\n",
       " 'Hyperio',\n",
       " 'Impact',\n",
       " 'Imprint Academic',\n",
       " 'Indigo',\n",
       " 'Inner Light - Global Communications',\n",
       " 'Inner Traditions',\n",
       " 'Inner Traditions International',\n",
       " 'Insel',\n",
       " 'Insel Frankfurt',\n",
       " 'Insight International',\n",
       " 'Interlink Publishing Group',\n",
       " 'International Code Council',\n",
       " 'International Polygonics',\n",
       " 'International Publishers',\n",
       " 'International Publishers (Nyc)',\n",
       " 'Island',\n",
       " 'Ivan R. Dee',\n",
       " 'Ivan R. Dee Publisher',\n",
       " 'Ivp Academic',\n",
       " 'Izdavačka Agencija \"Draganić\"',\n",
       " \"J'Ai Lu\",\n",
       " 'Jessica Kingsley Publishers',\n",
       " 'Jimmy Patterson',\n",
       " 'John F. Blair Publisher',\n",
       " 'John Wiley',\n",
       " 'John Wiley & Sons',\n",
       " 'Jonathan Cape',\n",
       " 'Jossey-Bass',\n",
       " 'Julia Macrae',\n",
       " 'Julie Andrews Collection',\n",
       " 'Jump At The Sun',\n",
       " 'K.G. Saur Verlag',\n",
       " 'Kabel Verlag Gmbh Ernst',\n",
       " 'Kaplan',\n",
       " 'Kensington',\n",
       " 'Kiepenheuer & Witsch',\n",
       " 'Kindle',\n",
       " 'Kingfisher',\n",
       " 'Kiwi',\n",
       " 'Klincksieck',\n",
       " 'Knopf Publishing Group',\n",
       " 'Knowledge Products',\n",
       " 'Kodansha',\n",
       " 'Kodansha America',\n",
       " 'Kodansha International',\n",
       " 'Konemann',\n",
       " 'Kregel Academic & Professional',\n",
       " 'Kuperard',\n",
       " \"L'Ecole Des Loisirs\",\n",
       " 'La Factoría De Ideas',\n",
       " 'Laffont',\n",
       " 'Lama Foundation (San Cristobal Nm)',\n",
       " 'Larousse',\n",
       " 'Larousse Kingfisher Chambers',\n",
       " 'Laurel',\n",
       " 'Lawbook Exchange Ltd.',\n",
       " 'Le Livre De Poche',\n",
       " 'Lectorum',\n",
       " 'Leisure',\n",
       " 'Lgf',\n",
       " 'Libraries Unlimited',\n",
       " 'Library Of America',\n",
       " 'Libros Para Ninos',\n",
       " 'Limelight',\n",
       " 'Limelight Editions',\n",
       " 'Limitless Corporation',\n",
       " 'Lippincott Williams & Wilkins',\n",
       " 'List Taschenbuch',\n",
       " 'Little Brown And Company',\n",
       " 'Liveright',\n",
       " 'Liveright Publishing Corp.',\n",
       " 'Livre De Poche',\n",
       " 'London : Collins 2004.',\n",
       " 'London : Faber 2002',\n",
       " 'Lonely Planet',\n",
       " 'Longman',\n",
       " 'Longman Publishing Group',\n",
       " 'Love Inspired',\n",
       " 'Loveswept',\n",
       " 'Lulu.Com',\n",
       " 'Lww',\n",
       " 'Lübbe',\n",
       " 'Macadam/Cage',\n",
       " 'Macmillan',\n",
       " 'Macmillan Audio',\n",
       " 'Macmillan Publ. Co.',\n",
       " 'Macmillan Uk',\n",
       " 'Manesse Verlag',\n",
       " 'Mariner Books',\n",
       " 'Mark Cahill Ministries',\n",
       " 'Martínez Roca',\n",
       " 'Marvel',\n",
       " 'Material World',\n",
       " 'Mcdougal Littel',\n",
       " 'Mcgraw-Hill',\n",
       " 'Mcgraw-Hill Companies',\n",
       " 'Mcgraw-Hill Education',\n",
       " 'Mcgraw-Hill Humanities/Social Sciences/Languages',\n",
       " 'Mcgraw-Hill Professional Publishing',\n",
       " 'Mcgraw-Hill Science/Engineering/Math',\n",
       " 'Mcgraw-Hill/Glencoe',\n",
       " 'Meredith Corporation',\n",
       " 'Mestas Ediciones',\n",
       " 'Methuen Drama',\n",
       " 'Michael Joseph',\n",
       " \"Michael O'Mara\",\n",
       " 'Midnight Ink',\n",
       " 'Millenium',\n",
       " 'Mills & Boon',\n",
       " 'Minnesota Heritage Publishing',\n",
       " 'Mira (Mills And Boon)',\n",
       " 'Miramax',\n",
       " 'Mirrorstone',\n",
       " 'Modern Library',\n",
       " 'Mondadori',\n",
       " 'Mondial',\n",
       " 'Monkfish Book Publishing',\n",
       " 'Monolith Graphics',\n",
       " 'Montena',\n",
       " 'Montlake Romance',\n",
       " 'Moody Publishers (Chicago)',\n",
       " 'Morpheus International',\n",
       " 'Motilal Banarsidass',\n",
       " 'Multnomah',\n",
       " 'Métailié',\n",
       " 'Nal',\n",
       " 'Nal Jam',\n",
       " 'Nal Trade',\n",
       " 'Nan A. Talese',\n",
       " 'National Gallery London',\n",
       " 'National Geographic',\n",
       " 'National Geographic Society',\n",
       " 'National Park Service',\n",
       " 'Naxos Audiobooks',\n",
       " 'Neil Wilson Publishing',\n",
       " 'Nelson Current',\n",
       " 'Nelson Thornes Ltd',\n",
       " 'New Directions',\n",
       " 'New Directions Publishing',\n",
       " 'Newmarket',\n",
       " 'Nicholas Brealey',\n",
       " 'Night Shade',\n",
       " 'Norma',\n",
       " 'Norma Editorial',\n",
       " 'Nostalgia Ventures',\n",
       " 'Not Avail',\n",
       " 'Nova Fronteira',\n",
       " 'Nymphenburger',\n",
       " 'Omnibus Hc Bei Bertelsmann',\n",
       " 'One Hour Entertainment',\n",
       " 'One World (Uk)',\n",
       " 'Onyx',\n",
       " 'Open Court',\n",
       " 'Orbit',\n",
       " 'Orchard',\n",
       " 'Orion Publishing Group',\n",
       " 'Our Daily Bread Publishing',\n",
       " 'Overeaters Anonymous Incorporated',\n",
       " 'Overlook Tp',\n",
       " 'Oxford University Press',\n",
       " 'Oxford University Press Usa',\n",
       " 'P. F. Collier And Sons',\n",
       " 'Palgrave Macmillan',\n",
       " 'Pan Australia',\n",
       " 'Pan Childrens',\n",
       " 'Pan Macmillan',\n",
       " 'Panamericana Editorial',\n",
       " 'Pantheon',\n",
       " 'Panther',\n",
       " 'Patmos',\n",
       " 'Paul S. Eriksson',\n",
       " 'Payot',\n",
       " 'Pearson',\n",
       " 'Pearson Education',\n",
       " 'Pearson Longman',\n",
       " 'Pen & Sword Military',\n",
       " 'Penguin',\n",
       " 'Penguin Books',\n",
       " 'Penguin Books Ltd',\n",
       " 'Penguin Classics',\n",
       " 'Perfectbound',\n",
       " 'Perigee Trade',\n",
       " 'Peter Owen Ltd',\n",
       " 'Peter Smith Publisher',\n",
       " 'Peter Smith Publisher Inc.',\n",
       " 'Phoenix',\n",
       " 'Phoenix Audio',\n",
       " 'Phébus',\n",
       " 'Piatkus',\n",
       " 'Picador',\n",
       " 'Picador Usa',\n",
       " 'Piemme',\n",
       " 'Pimlico',\n",
       " 'Pimsleur',\n",
       " 'Pinnacle',\n",
       " 'Pinter & Martin Ltd',\n",
       " 'Piper Taschenbuch',\n",
       " 'Piper Verlag',\n",
       " 'Planeta',\n",
       " 'Plaza & Janes Editores Sa',\n",
       " 'Plaza & Janés',\n",
       " 'Plaza & Janés Mexico',\n",
       " 'Plaza Y Janes',\n",
       " 'Plaza Y Janés',\n",
       " 'Plexus Publishing Ltd',\n",
       " 'Plume',\n",
       " 'Pocket Books',\n",
       " 'Points',\n",
       " 'Polychrome Publishing Corporation',\n",
       " 'Polygon',\n",
       " 'Pomegranate Communications',\n",
       " 'Poppy',\n",
       " 'Porrua',\n",
       " 'Portfolio',\n",
       " 'Possibilities',\n",
       " 'Praeger',\n",
       " 'Prentice Hall',\n",
       " 'Prentice Hall Ptr',\n",
       " 'Price Stern Sloan',\n",
       " 'Prima Games',\n",
       " 'Prima Lifestyles',\n",
       " 'Princeton University Press',\n",
       " 'Project Management Institute',\n",
       " 'Publicaffairs',\n",
       " 'Puffin Books',\n",
       " 'Push',\n",
       " 'Putnam Publishing Group',\n",
       " 'Puzzle-Roca',\n",
       " 'Puzzle-Via Magna',\n",
       " 'Pygmalion Editions',\n",
       " 'Quill',\n",
       " 'Quinteto',\n",
       " 'Raintree',\n",
       " 'Random House',\n",
       " 'Random House Audio',\n",
       " 'Random House Books For Young Readers',\n",
       " 'Razorbill',\n",
       " 'Rba Libros',\n",
       " 'Reclam',\n",
       " 'Reclam Ditzingen',\n",
       " 'Reclam Leipzig',\n",
       " 'Record',\n",
       " 'Red Dress Ink',\n",
       " 'Red Fox',\n",
       " 'Red Hen Pr',\n",
       " 'Regnery History',\n",
       " 'Rh Audio Price-Less',\n",
       " 'Rick Steves',\n",
       " 'Rivages',\n",
       " 'Riverhead Books',\n",
       " 'Rizzoli',\n",
       " 'Robert Laffont',\n",
       " 'Robert Rose',\n",
       " 'Roberts Rinehart Publishers',\n",
       " 'Roc',\n",
       " 'Roc Hardcover',\n",
       " 'Roc Trade',\n",
       " 'Roca Editorial',\n",
       " 'Rough Guides',\n",
       " 'Routledge',\n",
       " 'Rowman & Littlefield Publishers',\n",
       " 'Rowohlt',\n",
       " 'Rowohlt Taschenbuch Verlag Gmbh',\n",
       " 'Rowohlt Tb',\n",
       " 'Rowohlt Tb.',\n",
       " 'Rowohlt Verlag',\n",
       " 'Rp Minis',\n",
       " 'Rupa & Co',\n",
       " 'Ryland Peters & Small',\n",
       " 'Sagebrush',\n",
       " 'Salamandra',\n",
       " 'Salani',\n",
       " 'Saltriver',\n",
       " 'Samuel French Ltd',\n",
       " 'San Val',\n",
       " 'Saunders',\n",
       " 'Sceptre',\n",
       " 'Schirmer Mosel',\n",
       " 'Schirmer/Mosel',\n",
       " 'Schocken',\n",
       " 'Scholastic',\n",
       " 'Scholastic Paperbacks',\n",
       " 'School Specialty Publishing',\n",
       " 'Scribner',\n",
       " 'Secker',\n",
       " 'Secker And Warburg',\n",
       " 'Seix Barral',\n",
       " 'Semiotext(E)',\n",
       " 'Sensory Resources',\n",
       " 'Serpents Tail',\n",
       " 'Seuil',\n",
       " 'Shadow Mountain',\n",
       " 'Shambhala',\n",
       " 'Shaw',\n",
       " 'Shueisha',\n",
       " 'Sidgwick & Jackson Ltd',\n",
       " 'Siete Cuentos',\n",
       " 'Signet',\n",
       " 'Silhouette',\n",
       " 'Silhouette Desire',\n",
       " 'Silhouette Romance',\n",
       " 'Silhouette Special Edition',\n",
       " 'Simon & Schuster',\n",
       " 'Simon Schuster',\n",
       " 'Simple Productions',\n",
       " 'Sinauer Associates',\n",
       " 'Skylight Paths Publishing',\n",
       " 'Smart Pop',\n",
       " 'Smithmark Publishers',\n",
       " 'Soho Crime',\n",
       " 'Soundings',\n",
       " 'Sounds True',\n",
       " 'Sovereign World',\n",
       " 'Sparknotes',\n",
       " 'Speak',\n",
       " 'Spectra',\n",
       " 'Sphere',\n",
       " \"St. Martin'S Griffin\",\n",
       " \"St. Martin'S Paperbacks\",\n",
       " \"St. Martin'S Press\",\n",
       " 'Star Trek',\n",
       " 'Starfire',\n",
       " 'Starscape',\n",
       " 'Steerforth',\n",
       " 'Steidl',\n",
       " 'Stenhouse Publishers',\n",
       " 'Stewart Tabori And Chang',\n",
       " 'Stonewall Inn Editions',\n",
       " 'Sudamericana',\n",
       " 'Suhrkamp',\n",
       " 'Suma',\n",
       " 'Sunburst',\n",
       " 'Sutton',\n",
       " 'Sweet Valley',\n",
       " \"T&T Clark Int'L\",\n",
       " 'Tanglewood',\n",
       " 'Taplinger Publ. Company',\n",
       " 'Tarcher',\n",
       " 'Taschen',\n",
       " 'Taylor Productions Ltd',\n",
       " 'Tea',\n",
       " 'Teacher Created Resources',\n",
       " 'Teaching Resources',\n",
       " 'Thames & Hudson',\n",
       " 'Thames & Hudson Ltd',\n",
       " 'Thames Hudson',\n",
       " 'The Audio Partners',\n",
       " 'The Bodley Head Ltd',\n",
       " 'The Putnam & Grosset Group',\n",
       " 'Theatre Communications Group',\n",
       " 'Thomas Nelson',\n",
       " 'Time Life Medical',\n",
       " 'Timeless Texts',\n",
       " 'Titan',\n",
       " 'Tokyopop',\n",
       " 'Tom Doherty Associates',\n",
       " 'Tommy Nelson',\n",
       " 'Top Shelf Productions',\n",
       " 'Topaz',\n",
       " 'Tor Books',\n",
       " 'Tor Fantasy',\n",
       " 'Touchstone',\n",
       " 'Tougher Disguises',\n",
       " 'Transworld Publishers',\n",
       " 'Transworld Publishers Ltd',\n",
       " \"Travelers' Tales\",\n",
       " 'Treat Enterprises',\n",
       " 'Trine Day',\n",
       " 'Troll Communications',\n",
       " 'Tropismos',\n",
       " 'Tsr',\n",
       " 'Turtleback Books',\n",
       " 'Tusquets',\n",
       " 'Twin Palms Publishers',\n",
       " 'Two Lions',\n",
       " 'Tyndale Momentum',\n",
       " 'Ullstein',\n",
       " 'Ullstein Buchverlage Gmbh & Co. Kg / Ullstein Tas',\n",
       " 'Ullstein Tb',\n",
       " 'Umbriel',\n",
       " 'Universal Publishers',\n",
       " 'Universe Publishing(Ny)',\n",
       " 'University Of California Press',\n",
       " 'University Of Chicago Press',\n",
       " 'Us Green Building Council',\n",
       " 'Verba Mundi',\n",
       " 'Vermilion',\n",
       " 'Vertigo',\n",
       " 'Victor Gollancz',\n",
       " 'Vida',\n",
       " 'Viking',\n",
       " 'Viking Adult',\n",
       " 'Viking Juvenile',\n",
       " 'Viking Uk',\n",
       " 'Villard',\n",
       " 'Vince Emery Productions',\n",
       " 'Vintage',\n",
       " 'Virago',\n",
       " 'Virago Uk',\n",
       " 'Vision',\n",
       " 'Vision Forum',\n",
       " 'Vivendi',\n",
       " 'Viz Media',\n",
       " 'Viz Media Llc',\n",
       " 'Voice',\n",
       " 'Volo',\n",
       " 'Voyager',\n",
       " 'W. W. Norton & Company',\n",
       " 'W. W. Norton Company',\n",
       " 'Walker',\n",
       " 'Walter De Gruyter',\n",
       " 'Walter Foster Publishing',\n",
       " 'Warner Adult',\n",
       " 'Warner Books',\n",
       " 'Warner Forever',\n",
       " 'Warner Vision',\n",
       " 'Wasendorf & Associates Inc',\n",
       " 'Washington Square Press',\n",
       " 'Watkins',\n",
       " 'Watson-Guptill',\n",
       " \"Webster'S New World\",\n",
       " 'Weidenfeld & Nicolson',\n",
       " 'White Wolf Games Studio',\n",
       " 'Wildstorm',\n",
       " 'Wiley',\n",
       " 'Wiley (Tp)',\n",
       " 'Wilhelm Goldmann Verlag Gmbh',\n",
       " 'William Heinemann',\n",
       " 'William Morrow',\n",
       " 'William Morrow Paperbacks',\n",
       " 'Windsor Golden Series',\n",
       " 'Wings',\n",
       " 'Wipf & Stock Publishers',\n",
       " 'Wizards Of The Coast',\n",
       " 'Wordsworth Editions',\n",
       " 'Wyatt Book',\n",
       " 'Xlibris Corporation',\n",
       " 'Y Lolfa',\n",
       " 'Yale University Press',\n",
       " 'Yapı Kredi Yayınları',\n",
       " 'Yearling',\n",
       " 'Yoruba Theological Archministry',\n",
       " 'Yosemite Conservancy',\n",
       " 'Your Coach Digital',\n",
       " 'Zebra',\n",
       " 'Zondervan',\n",
       " 'Éditions 10/18',\n",
       " 'Éditions De Minuit',\n",
       " 'Éditions Du Rocher',\n",
       " 'Эксмо',\n",
       " 'ガンガンコミックス',\n",
       " 'ビブロス',\n",
       " '小学館',\n",
       " '小学館 [ShōGakukan]',\n",
       " '時報出版',\n",
       " '東立',\n",
       " '皇冠文化出版有限公司',\n",
       " '聯經出版事業股份有限公司',\n",
       " '英文漢聲出版股份有限公司',\n",
       " '角川書店 (Kadokawa Shoten)',\n",
       " '講談社',\n",
       " '集英社']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['publisher'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20ba28",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So everything is looking good. We've chopped the list of publishers to a little over half of what it used to be. I'm a little tired of trying to automate everything (fuzzywuzzy was pain to figure out) so I decide to just roll up my sleeves and pare down the list more manually. I will mostly be using regex with a custom function to remove extra things I don't want, and the `df.loc` and `str.contains` methods to normalize larger publishers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5871017c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_regex_pattern(regex, column='publisher'):\n",
    "    pattern = re.compile(regex)\n",
    "    df[column] = df[column].str.replace(pattern, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bf6ff4f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhous\\AppData\\Local\\Temp\\ipykernel_49724\\3376952053.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['publisher'] = df['publisher'].str.replace(r'\\s+And\\s+', ' & ')\n"
     ]
    }
   ],
   "source": [
    "# Remove anything inside parenthesis\n",
    "remove_regex_pattern(r'\\s*\\([^)]*\\)')\n",
    "\n",
    "# Remove Ltd\n",
    "remove_regex_pattern(r'\\bLtd\\.?\\b')\n",
    "\n",
    "# Remove Inc and Inc.\n",
    "remove_regex_pattern(r'\\bInc\\.?\\b')\n",
    "\n",
    "#Remove Publisher and Publishers\n",
    "remove_regex_pattern(r'.Publisher(s)?\\b')\n",
    "\n",
    "# Remove wierd space plus period\n",
    "remove_regex_pattern(r'\\s\\.')\n",
    "\n",
    "# Remove 'Tb'\n",
    "remove_regex_pattern(r'\\sTb\\.?')\n",
    "\n",
    "# Remove Verlag\n",
    "remove_regex_pattern(r'\\sVerlag')\n",
    "\n",
    "df['publisher'] = df['publisher'].str.replace(r'\\s+And\\s+', ' & ')\n",
    "df['publisher'] = df['publisher'].str.replace(r'Pubns', '')\n",
    "\n",
    "# Change Bbc to BBC because it was bothering me\n",
    "df['publisher'] = df['publisher'].str.replace(r'Bbc', 'BBC')\n",
    "\n",
    "# Melt Bloomsbury companies into single publisher\n",
    "df.loc[df['publisher'].str.contains('Bloomsbury'), 'publisher'] = 'Bloomsbury Publishing'\n",
    "\n",
    "# Same with Gallimard\n",
    "df.loc[df['publisher'].str.contains('Gallimard'), 'publisher'] = 'Gallimard'\n",
    "\n",
    "# Hachette\n",
    "df.loc[df['publisher'].str.contains('Hachette'), 'publisher'] = 'Hachette'\n",
    "\n",
    "# Harlequin\n",
    "df.loc[df['publisher'].str.contains('Harlequin'), 'publisher'] = 'Harlequin'\n",
    "\n",
    "# HarperCollins\n",
    "df.loc[df['publisher'].str.contains('Harper'), 'publisher'] = 'HarperCollins'\n",
    "\n",
    "# Headline\n",
    "df.loc[df['publisher'].str.contains('Headline'), 'publisher'] = 'Headline'\n",
    "\n",
    "# Kodansha\n",
    "df.loc[df['publisher'].str.contains('Kodansha'), 'publisher'] = 'Kodansha'\n",
    "\n",
    "# Macmillan\n",
    "df.loc[df['publisher'].str.contains('Macmillan'), 'publisher'] = 'Macmillan'\n",
    "\n",
    "# Macgraw-Hill\n",
    "df.loc[df['publisher'].str.contains('Mcgraw-Hill'), 'publisher'] = 'Mcgraw-Hill'\n",
    "\n",
    "# Penguin\n",
    "df.loc[df['publisher'].str.contains('Penguin'), 'publisher'] = 'Penguin'\n",
    "\n",
    "# Random House\n",
    "df.loc[df['publisher'].str.contains('Random House'), 'publisher'] = 'Random House'\n",
    "\n",
    "# Reclam\n",
    "df.loc[df['publisher'].str.contains('Reclam'), 'publisher'] = 'Reclam'\n",
    "\n",
    "# Silhouette\n",
    "df.loc[df['publisher'].str.contains('Silhouette'), 'publisher'] = 'Silhouette'\n",
    "\n",
    "# St. Martin's\n",
    "df.loc[df['publisher'].str.contains('St. Martin'), 'publisher'] = \"St. Martin's\"\n",
    "\n",
    "# Viking\n",
    "df.loc[df['publisher'].str.contains('Viking'), 'publisher'] = 'Viking'\n",
    "\n",
    "# Warner\n",
    "df.loc[df['publisher'].str.contains('Warner'), 'publisher'] = 'Warner Books'\n",
    "\n",
    "# Strip leading/trailing whitespaces I might have created\n",
    "df['publisher'] = df['publisher'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49bd8351",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Publishers: 771\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Publishers: {len(df[\"publisher\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e3709de4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10/18',\n",
       " '1St Book Library',\n",
       " 'Aa World Services',\n",
       " 'Abacus',\n",
       " 'Abstract Studio',\n",
       " 'Academy Chicago',\n",
       " 'Ace',\n",
       " 'Actes Sud',\n",
       " 'Addison Wesley',\n",
       " 'Addison-Wesley Professional',\n",
       " 'Adv Manga',\n",
       " 'Aegypan',\n",
       " 'Aha! Process',\n",
       " 'Ait Planet Lar',\n",
       " 'Aladdin',\n",
       " 'Albert Whitman Company',\n",
       " 'Albin Michel',\n",
       " 'Alcoholics Anonymous World Services',\n",
       " 'Alderac Entertainment Group',\n",
       " 'Alfabeta Bokförlag',\n",
       " 'Alfaguara',\n",
       " 'Alfaguara Infantil',\n",
       " 'Alfred A. Knopf',\n",
       " 'Alianza Editorial',\n",
       " 'Allen & Ulwin',\n",
       " 'Allen Lane',\n",
       " 'Allworth',\n",
       " 'Alpha',\n",
       " 'Amadeus',\n",
       " 'Amereon Limited',\n",
       " \"America'S Test Kitchen\",\n",
       " 'American Diabetes Association',\n",
       " 'Amistad',\n",
       " 'Amr/Advanced Management Reports',\n",
       " 'Anagrama',\n",
       " 'Anchor',\n",
       " 'Anchor Books',\n",
       " 'Andrews & Mcmeel',\n",
       " 'Apple',\n",
       " 'Archaia',\n",
       " 'Arden Shakespeare',\n",
       " 'Aris & Phillips',\n",
       " 'Arkana',\n",
       " 'Arrow',\n",
       " 'Arthur A. Levine',\n",
       " 'Artisan',\n",
       " 'Aspect',\n",
       " 'Atheneum',\n",
       " 'Audio Literature',\n",
       " 'Audio Partners',\n",
       " 'Audio Renaissance',\n",
       " 'Audiogo',\n",
       " 'Audiotext',\n",
       " 'Augsburg Fortress Publishing',\n",
       " 'Aurum',\n",
       " 'Authorhouse',\n",
       " 'Avon',\n",
       " 'BBC Audiobooks',\n",
       " 'BBC Audiobooks America',\n",
       " 'BBC Physical Audio',\n",
       " 'BBC Worldwide',\n",
       " 'Babel',\n",
       " 'Back Bay Books',\n",
       " 'Backinprint.Com',\n",
       " 'Ballantine Books',\n",
       " 'Bantam',\n",
       " 'Bantam Books',\n",
       " 'Barnes Noble Classics',\n",
       " 'Barrington Stoke',\n",
       " 'Basic Books',\n",
       " 'Bastei Lübbe',\n",
       " 'Batsford',\n",
       " 'Bcp/Duckworth Publishing',\n",
       " 'Be Beautiful',\n",
       " 'Beltz Und Gelberg',\n",
       " 'Benjamin Cummings',\n",
       " 'Benziger',\n",
       " 'Berkley',\n",
       " 'Berkley Books',\n",
       " 'Berlitz Kids',\n",
       " 'Berrett-Koehler',\n",
       " 'Bertrand',\n",
       " 'Between The Lines Productions',\n",
       " 'Bibliolife',\n",
       " 'Big Finish',\n",
       " 'Birlinn',\n",
       " 'Black Dog & Leventhal',\n",
       " 'Black Swan',\n",
       " 'Blackstone Publishing',\n",
       " 'Blanvalet Gmbh',\n",
       " 'Blanvalet Taschenbuch',\n",
       " 'Blood Moon Productions',\n",
       " 'Bloomsbury Publishing',\n",
       " 'Blu',\n",
       " 'Bolchazy-Carducci',\n",
       " 'Book Of The Month Club',\n",
       " 'Bookclub-In-A-Box',\n",
       " 'Booksales',\n",
       " 'Bradygames',\n",
       " 'Bragelonne',\n",
       " 'Brava',\n",
       " 'Brill/Rodopi',\n",
       " 'Brilliance Audio',\n",
       " 'British Academy',\n",
       " 'British Film Institute',\n",
       " 'British Library',\n",
       " 'Broadway Books',\n",
       " 'Brown Son & Ferguson',\n",
       " 'Bruno Gmünder',\n",
       " 'Bryn Mawr Commentaries',\n",
       " 'Btb',\n",
       " 'Bulfinch',\n",
       " 'Bureau Of Public Secrets',\n",
       " 'Business Plus',\n",
       " 'Byblos',\n",
       " 'C. Bange',\n",
       " 'Caedmon',\n",
       " 'Cambridge University Press',\n",
       " 'Candlewick',\n",
       " 'Cardoza',\n",
       " 'Carl Hanser',\n",
       " 'Carlsen',\n",
       " 'Carole Marsh Mysteries',\n",
       " 'Cartago',\n",
       " 'Cartwheel',\n",
       " 'Casa Creacion',\n",
       " 'Catholic Book Publishing',\n",
       " 'Celestial Arts',\n",
       " 'Center Point',\n",
       " 'Century',\n",
       " 'Chaosium',\n",
       " 'Charlesbridge',\n",
       " 'Charnwood',\n",
       " 'Chatto & Windus',\n",
       " 'Chatto Windus',\n",
       " 'Cherry Lane Music Company',\n",
       " \"Child'S Play International\",\n",
       " 'Churchill Livingstone',\n",
       " 'Cisne',\n",
       " 'City Lights',\n",
       " 'Claassen',\n",
       " 'Clarkson Potter',\n",
       " 'Cliffs Notes',\n",
       " 'Cmx',\n",
       " 'Collins Design',\n",
       " 'Collins Reference',\n",
       " 'Columbia Pictures',\n",
       " 'Comicsone Corporation',\n",
       " 'Companhia Das Letras',\n",
       " 'Contemporary French Fiction',\n",
       " 'Continuum',\n",
       " \"Cook'S Illustrated\",\n",
       " 'Cooper Square',\n",
       " 'Corgi',\n",
       " 'Corgi Childrens',\n",
       " 'Coronet',\n",
       " 'Counterpoint',\n",
       " 'Counterpoint Llc',\n",
       " 'Course Technology',\n",
       " 'Crescent',\n",
       " 'Critica',\n",
       " 'Crossroad',\n",
       " 'Crown Business',\n",
       " 'Crown Forum',\n",
       " 'Crystal Clarity',\n",
       " 'Cybereditions Corp',\n",
       " 'Cátedra',\n",
       " 'Dabel Brothers Productions',\n",
       " 'Dabel Brothers Publishing',\n",
       " 'Daimon',\n",
       " 'Dark Horse',\n",
       " 'Dark Horse Manga',\n",
       " 'Darton Longman & Todd',\n",
       " 'David C Cook',\n",
       " 'David C. Cook',\n",
       " 'David R. Godine',\n",
       " 'Daw',\n",
       " 'Dc Comics',\n",
       " 'De Boekerij',\n",
       " 'Debolsillo',\n",
       " 'Dedalus',\n",
       " 'Dedalus Limited',\n",
       " 'Del Rey',\n",
       " 'Del Rey Books',\n",
       " 'Dell',\n",
       " 'Delta',\n",
       " 'Deodand',\n",
       " 'Destino Ediciones',\n",
       " 'Destiny Image Incorporated',\n",
       " 'Deutscher Taschenbuch',\n",
       " \"Devil'S Due Publishing\",\n",
       " 'Dhv Der Hörverlag',\n",
       " 'Diana',\n",
       " 'Digireads.Com',\n",
       " 'Diogenes',\n",
       " 'Disney Editions',\n",
       " 'Disney Enterprises',\n",
       " 'Disney-Hyperion',\n",
       " 'Dk',\n",
       " 'Dk Children',\n",
       " 'Dk Publishing',\n",
       " 'Dodd Mead; 1St Edition',\n",
       " 'Dorling Kindersley Children',\n",
       " 'Doubleday',\n",
       " 'Doubleday Canada',\n",
       " 'Doubleday Publishing',\n",
       " 'Douglas & Mcintyre',\n",
       " 'Douglas Mcintyre',\n",
       " 'Dover Publications',\n",
       " 'Dr. Master Productions',\n",
       " 'Dramatists Play Service',\n",
       " 'Drawn & Quarterly',\n",
       " 'Droemer Knaur',\n",
       " 'Dtv',\n",
       " 'Dundurn',\n",
       " 'Dutton',\n",
       " 'Dutton Adult',\n",
       " 'Dutton Juvenile',\n",
       " 'Ediciones B',\n",
       " 'Ediciones Glénat España',\n",
       " 'Ediciones Urano',\n",
       " 'Edimat Libros',\n",
       " 'Editions 10/18',\n",
       " 'Editions Du Rocher',\n",
       " 'Editorial Diana',\n",
       " 'Editorial Juventud',\n",
       " 'Editorial Presença',\n",
       " 'Editorial Rm',\n",
       " 'Element',\n",
       " 'Ember',\n",
       " 'Emece Editores',\n",
       " 'Emecé Editores',\n",
       " 'Eminent Lives',\n",
       " 'Eos',\n",
       " 'Eros Comix',\n",
       " 'Europa Editions',\n",
       " 'Evans Brothers',\n",
       " \"Everyman'S Library\",\n",
       " 'Exact Change',\n",
       " 'F. Meiner',\n",
       " 'Faber & Faber',\n",
       " 'Faber & Faber Limited',\n",
       " 'Faber Faber',\n",
       " 'Faithwords',\n",
       " 'Fanfare',\n",
       " 'Fantagraphics',\n",
       " 'Fantasy Flight Games',\n",
       " 'Farrar Straus & Giroux',\n",
       " 'Fasa Corp.',\n",
       " 'Fasa Corporation',\n",
       " 'Fawcett',\n",
       " 'Fawcett Coventry',\n",
       " 'Fawcett Crest',\n",
       " 'Feiwel & Friends',\n",
       " 'Felony & Mayhem',\n",
       " 'Festival',\n",
       " 'Findakly',\n",
       " 'Firebird',\n",
       " 'Fireside',\n",
       " 'Fischer',\n",
       " 'Fischer Taschenbuch',\n",
       " 'Five Star',\n",
       " 'Five Star Trade',\n",
       " 'Flamingo',\n",
       " 'Focus',\n",
       " 'Folio',\n",
       " 'Folio Histoire',\n",
       " 'Fonolibro',\n",
       " 'Fontana',\n",
       " 'Forge',\n",
       " 'Fount',\n",
       " 'Four Ninety-Eight Productions',\n",
       " 'Fourth Estate',\n",
       " 'Fourth Estate Paperbacks',\n",
       " 'Franklin Watts',\n",
       " 'Free Press',\n",
       " 'French & European',\n",
       " 'Futura',\n",
       " \"G.P. Putnam'S Sons\",\n",
       " 'Gale Cengage',\n",
       " 'Gallimard',\n",
       " 'Gallopade International',\n",
       " 'Gamble Guides',\n",
       " 'Games Workshop',\n",
       " 'Geddes & Grosset',\n",
       " 'George Braziller',\n",
       " 'Gibbs Smith',\n",
       " 'Globe',\n",
       " 'Glénat',\n",
       " 'Gold Eagle',\n",
       " 'Golden/Disney',\n",
       " 'Goldmann',\n",
       " 'Gollancz',\n",
       " 'Gotham',\n",
       " 'Grafton',\n",
       " 'Gramedia Pustaka Utama',\n",
       " 'Gramercy',\n",
       " 'Grand Central Publishing',\n",
       " 'Granta Uk',\n",
       " 'Grasset',\n",
       " 'Green Integer',\n",
       " 'Greenwood',\n",
       " 'Grijalbo',\n",
       " 'Grijalbo Mondadori Sa',\n",
       " 'Grosset & Dunlap',\n",
       " 'Grove Press',\n",
       " 'Grove Weidenfeld',\n",
       " 'Grupo Océano',\n",
       " 'Hachette',\n",
       " 'Hackett Publishing Company',\n",
       " 'Hakusen Sha',\n",
       " 'Hal Leonard Pub Corp',\n",
       " 'Hamish Hamilton',\n",
       " 'Harcourt',\n",
       " 'Harcourt Brace Jovanovich',\n",
       " 'Harcourt Brace Jovanovich/Harvest',\n",
       " 'Hard Crime Case',\n",
       " 'Harlequin',\n",
       " 'Harmony',\n",
       " 'HarperCollins',\n",
       " 'Harry N. Abrams',\n",
       " 'Harvard University Press',\n",
       " 'Harvest / Harcourt',\n",
       " 'Hci',\n",
       " 'Headline',\n",
       " 'Health Communications',\n",
       " 'Hearst Communications',\n",
       " 'Heinemann',\n",
       " 'Heinemann Drama',\n",
       " 'Heinemann-Octopus',\n",
       " 'Heinle',\n",
       " 'Henry Holt',\n",
       " 'Henry Holt & Co.',\n",
       " 'Heyne',\n",
       " 'Highbridge Audio',\n",
       " 'Hill & Wang',\n",
       " 'Hill & Wang Publ.',\n",
       " 'Hiperión',\n",
       " 'Hj Kramer',\n",
       " 'Hmh Books For Young Readers',\n",
       " 'Hodder',\n",
       " 'Hodder & Stoughton',\n",
       " 'Hodder & Stoughton Educational Division',\n",
       " 'Hodder Mobius',\n",
       " 'Hodder Wayland',\n",
       " 'Holt Mcdougal',\n",
       " 'Holt Rinehart & Winston',\n",
       " 'Houghton Mifflin Harcourt',\n",
       " 'Hqn',\n",
       " 'Hungry Minds',\n",
       " 'Hyperio',\n",
       " 'Impact',\n",
       " 'Imprint Academic',\n",
       " 'Indigo',\n",
       " 'Inner Light - Global Communications',\n",
       " 'Inner Traditions',\n",
       " 'Inner Traditions International',\n",
       " 'Insel',\n",
       " 'Insel Frankfurt',\n",
       " 'Insight International',\n",
       " 'Interlink Publishing Group',\n",
       " 'International',\n",
       " 'International Code Council',\n",
       " 'International Polygonics',\n",
       " 'Island',\n",
       " 'Ivan R. Dee',\n",
       " 'Ivp Academic',\n",
       " 'Izdavačka Agencija \"Draganić\"',\n",
       " \"J'Ai Lu\",\n",
       " 'Jessica Kingsley',\n",
       " 'Jimmy Patterson',\n",
       " 'John F. Blair',\n",
       " 'John Wiley',\n",
       " 'John Wiley & Sons',\n",
       " 'Jonathan Cape',\n",
       " 'Jossey-Bass',\n",
       " 'Julia Macrae',\n",
       " 'Julie Andrews Collection',\n",
       " 'Jump At The Sun',\n",
       " 'K.G. Saur',\n",
       " 'Kabel Gmbh Ernst',\n",
       " 'Kaplan',\n",
       " 'Kensington',\n",
       " 'Kiepenheuer & Witsch',\n",
       " 'Kindle',\n",
       " 'Kingfisher',\n",
       " 'Kiwi',\n",
       " 'Klincksieck',\n",
       " 'Knopf Publishing Group',\n",
       " 'Knowledge Products',\n",
       " 'Kodansha',\n",
       " 'Konemann',\n",
       " 'Kregel Academic & Professional',\n",
       " 'Kuperard',\n",
       " \"L'Ecole Des Loisirs\",\n",
       " 'La Factoría De Ideas',\n",
       " 'Laffont',\n",
       " 'Lama Foundation',\n",
       " 'Larousse',\n",
       " 'Larousse Kingfisher Chambers',\n",
       " 'Laurel',\n",
       " 'Lawbook Exchange',\n",
       " 'Le Livre De Poche',\n",
       " 'Lectorum',\n",
       " 'Leisure',\n",
       " 'Lgf',\n",
       " 'Libraries Unlimited',\n",
       " 'Library Of America',\n",
       " 'Libros Para Ninos',\n",
       " 'Limelight',\n",
       " 'Limelight Editions',\n",
       " 'Limitless Corporation',\n",
       " 'Lippincott Williams & Wilkins',\n",
       " 'List Taschenbuch',\n",
       " 'Little Brown & Company',\n",
       " 'Liveright',\n",
       " 'Liveright Publishing Corp.',\n",
       " 'Livre De Poche',\n",
       " 'London : Collins 2004.',\n",
       " 'London : Faber 2002',\n",
       " 'Lonely Planet',\n",
       " 'Longman',\n",
       " 'Longman Publishing Group',\n",
       " 'Love Inspired',\n",
       " 'Loveswept',\n",
       " 'Lulu.Com',\n",
       " 'Lww',\n",
       " 'Lübbe',\n",
       " 'Macadam/Cage',\n",
       " 'Macmillan',\n",
       " 'Manesse',\n",
       " 'Mariner Books',\n",
       " 'Mark Cahill Ministries',\n",
       " 'Martínez Roca',\n",
       " 'Marvel',\n",
       " 'Material World',\n",
       " 'Mcdougal Littel',\n",
       " 'Mcgraw-Hill',\n",
       " 'Meredith Corporation',\n",
       " 'Mestas Ediciones',\n",
       " 'Methuen Drama',\n",
       " 'Michael Joseph',\n",
       " \"Michael O'Mara\",\n",
       " 'Midnight Ink',\n",
       " 'Millenium',\n",
       " 'Mills & Boon',\n",
       " 'Minnesota Heritage Publishing',\n",
       " 'Mira',\n",
       " 'Miramax',\n",
       " 'Mirrorstone',\n",
       " 'Modern Library',\n",
       " 'Mondadori',\n",
       " 'Mondial',\n",
       " 'Monkfish Book Publishing',\n",
       " 'Monolith Graphics',\n",
       " 'Montena',\n",
       " 'Montlake Romance',\n",
       " 'Moody',\n",
       " 'Morpheus International',\n",
       " 'Motilal Banarsidass',\n",
       " 'Multnomah',\n",
       " 'Métailié',\n",
       " 'Nal',\n",
       " 'Nal Jam',\n",
       " 'Nal Trade',\n",
       " 'Nan A. Talese',\n",
       " 'National Gallery London',\n",
       " 'National Geographic',\n",
       " 'National Geographic Society',\n",
       " 'National Park Service',\n",
       " 'Naxos Audiobooks',\n",
       " 'Neil Wilson Publishing',\n",
       " 'Nelson Current',\n",
       " 'Nelson Thornes',\n",
       " 'New Directions',\n",
       " 'New Directions Publishing',\n",
       " 'Newmarket',\n",
       " 'Nicholas Brealey',\n",
       " 'Night Shade',\n",
       " 'Norma',\n",
       " 'Norma Editorial',\n",
       " 'Nostalgia Ventures',\n",
       " 'Not Avail',\n",
       " 'Nova Fronteira',\n",
       " 'Nymphenburger',\n",
       " 'Omnibus Hc Bei Bertelsmann',\n",
       " 'One Hour Entertainment',\n",
       " 'One World',\n",
       " 'Onyx',\n",
       " 'Open Court',\n",
       " 'Orbit',\n",
       " 'Orchard',\n",
       " 'Orion Publishing Group',\n",
       " 'Our Daily Bread Publishing',\n",
       " 'Overeaters Anonymous Incorporated',\n",
       " 'Overlook Tp',\n",
       " 'Oxford University Press',\n",
       " 'Oxford University Press Usa',\n",
       " 'P. F. Collier & Sons',\n",
       " 'Pan Australia',\n",
       " 'Pan Childrens',\n",
       " 'Panamericana Editorial',\n",
       " 'Pantheon',\n",
       " 'Panther',\n",
       " 'Patmos',\n",
       " 'Paul S. Eriksson',\n",
       " 'Payot',\n",
       " 'Pearson',\n",
       " 'Pearson Education',\n",
       " 'Pearson Longman',\n",
       " 'Pen & Sword Military',\n",
       " 'Penguin',\n",
       " 'Perfectbound',\n",
       " 'Perigee Trade',\n",
       " 'Peter Owen',\n",
       " 'Peter Smith',\n",
       " 'Phoenix',\n",
       " 'Phoenix Audio',\n",
       " 'Phébus',\n",
       " 'Piatkus',\n",
       " 'Picador',\n",
       " 'Picador Usa',\n",
       " 'Piemme',\n",
       " 'Pimlico',\n",
       " 'Pimsleur',\n",
       " 'Pinnacle',\n",
       " 'Pinter & Martin',\n",
       " 'Piper',\n",
       " 'Piper Taschenbuch',\n",
       " 'Planeta',\n",
       " 'Plaza & Janes Editores Sa',\n",
       " 'Plaza & Janés',\n",
       " 'Plaza & Janés Mexico',\n",
       " 'Plaza Y Janes',\n",
       " 'Plaza Y Janés',\n",
       " 'Plexus Publishing',\n",
       " 'Plume',\n",
       " 'Pocket Books',\n",
       " 'Points',\n",
       " 'Polychrome Publishing Corporation',\n",
       " 'Polygon',\n",
       " 'Pomegranate Communications',\n",
       " 'Poppy',\n",
       " 'Porrua',\n",
       " 'Portfolio',\n",
       " 'Possibilities',\n",
       " 'Praeger',\n",
       " 'Prentice Hall',\n",
       " 'Prentice Hall Ptr',\n",
       " 'Price Stern Sloan',\n",
       " 'Prima Games',\n",
       " 'Prima Lifestyles',\n",
       " 'Princeton University Press',\n",
       " 'Project Management Institute',\n",
       " 'Publicaffairs',\n",
       " 'Puffin Books',\n",
       " 'Push',\n",
       " 'Putnam Publishing Group',\n",
       " 'Puzzle-Roca',\n",
       " 'Puzzle-Via Magna',\n",
       " 'Pygmalion Editions',\n",
       " 'Quill',\n",
       " 'Quinteto',\n",
       " 'Raintree',\n",
       " 'Random House',\n",
       " 'Razorbill',\n",
       " 'Rba Libros',\n",
       " 'Reclam',\n",
       " 'Record',\n",
       " 'Red Dress Ink',\n",
       " 'Red Fox',\n",
       " 'Red Hen Pr',\n",
       " 'Regnery History',\n",
       " 'Rh Audio Price-Less',\n",
       " 'Rick Steves',\n",
       " 'Rivages',\n",
       " 'Riverhead Books',\n",
       " 'Rizzoli',\n",
       " 'Robert Laffont',\n",
       " 'Robert Rose',\n",
       " 'Roberts Rinehart',\n",
       " 'Roc',\n",
       " 'Roc Hardcover',\n",
       " 'Roc Trade',\n",
       " 'Roca Editorial',\n",
       " 'Rough Guides',\n",
       " 'Routledge',\n",
       " 'Rowman & Littlefield',\n",
       " 'Rowohlt',\n",
       " 'Rowohlt Taschenbuch Gmbh',\n",
       " 'Rp Minis',\n",
       " 'Rupa & Co',\n",
       " 'Ryland Peters & Small',\n",
       " 'Sagebrush',\n",
       " 'Salamandra',\n",
       " 'Salani',\n",
       " 'Saltriver',\n",
       " 'Samuel French',\n",
       " 'San Val',\n",
       " 'Saunders',\n",
       " 'Sceptre',\n",
       " 'Schirmer Mosel',\n",
       " 'Schirmer/Mosel',\n",
       " 'Schocken',\n",
       " 'Scholastic',\n",
       " 'Scholastic Paperbacks',\n",
       " 'School Specialty Publishing',\n",
       " 'Scribner',\n",
       " 'Secker',\n",
       " 'Secker & Warburg',\n",
       " 'Seix Barral',\n",
       " 'Semiotext',\n",
       " 'Sensory Resources',\n",
       " 'Serpents Tail',\n",
       " 'Seuil',\n",
       " 'Shadow Mountain',\n",
       " 'Shambhala',\n",
       " 'Shaw',\n",
       " 'Shueisha',\n",
       " 'Sidgwick & Jackson',\n",
       " 'Siete Cuentos',\n",
       " 'Signet',\n",
       " 'Silhouette',\n",
       " 'Simon & Schuster',\n",
       " 'Simon Schuster',\n",
       " 'Simple Productions',\n",
       " 'Sinauer Associates',\n",
       " 'Skylight Paths Publishing',\n",
       " 'Smart Pop',\n",
       " 'Smithmark',\n",
       " 'Soho Crime',\n",
       " 'Soundings',\n",
       " 'Sounds True',\n",
       " 'Sovereign World',\n",
       " 'Sparknotes',\n",
       " 'Speak',\n",
       " 'Spectra',\n",
       " 'Sphere',\n",
       " \"St. Martin's\",\n",
       " 'Star Trek',\n",
       " 'Starfire',\n",
       " 'Starscape',\n",
       " 'Steerforth',\n",
       " 'Steidl',\n",
       " 'Stenhouse',\n",
       " 'Stewart Tabori & Chang',\n",
       " 'Stonewall Inn Editions',\n",
       " 'Sudamericana',\n",
       " 'Suhrkamp',\n",
       " 'Suma',\n",
       " 'Sunburst',\n",
       " 'Sutton',\n",
       " 'Sweet Valley',\n",
       " \"T&T Clark Int'L\",\n",
       " 'Tanglewood',\n",
       " 'Taplinger Publ. Company',\n",
       " 'Tarcher',\n",
       " 'Taschen',\n",
       " 'Taylor Productions',\n",
       " 'Tea',\n",
       " 'Teacher Created Resources',\n",
       " 'Teaching Resources',\n",
       " 'Thames & Hudson',\n",
       " 'Thames Hudson',\n",
       " 'The Audio Partners',\n",
       " 'The Bodley Head',\n",
       " 'The Putnam & Grosset Group',\n",
       " 'Theatre Communications Group',\n",
       " 'Thomas Nelson',\n",
       " 'Time Life Medical',\n",
       " 'Timeless Texts',\n",
       " 'Titan',\n",
       " 'Tokyopop',\n",
       " 'Tom Doherty Associates',\n",
       " 'Tommy Nelson',\n",
       " 'Top Shelf Productions',\n",
       " 'Topaz',\n",
       " 'Tor Books',\n",
       " 'Tor Fantasy',\n",
       " 'Touchstone',\n",
       " 'Tougher Disguises',\n",
       " 'Transworld',\n",
       " \"Travelers' Tales\",\n",
       " 'Treat Enterprises',\n",
       " 'Trine Day',\n",
       " 'Troll Communications',\n",
       " 'Tropismos',\n",
       " 'Tsr',\n",
       " 'Turtleback Books',\n",
       " 'Tusquets',\n",
       " 'Twin Palms',\n",
       " 'Two Lions',\n",
       " 'Tyndale Momentum',\n",
       " 'Ullstein',\n",
       " 'Ullstein Buchverlage Gmbh & Co. Kg / Ullstein Tas',\n",
       " 'Umbriel',\n",
       " 'Universal',\n",
       " 'Universe Publishing',\n",
       " 'University Of California Press',\n",
       " 'University Of Chicago Press',\n",
       " 'Us Green Building Council',\n",
       " 'Verba Mundi',\n",
       " 'Vermilion',\n",
       " 'Vertigo',\n",
       " 'Victor Gollancz',\n",
       " 'Vida',\n",
       " 'Viking',\n",
       " 'Villard',\n",
       " 'Vince Emery Productions',\n",
       " 'Vintage',\n",
       " 'Virago',\n",
       " 'Virago Uk',\n",
       " 'Vision',\n",
       " 'Vision Forum',\n",
       " 'Vivendi',\n",
       " 'Viz Media',\n",
       " 'Viz Media Llc',\n",
       " 'Voice',\n",
       " 'Volo',\n",
       " 'Voyager',\n",
       " 'W. W. Norton & Company',\n",
       " 'W. W. Norton Company',\n",
       " 'Walker',\n",
       " 'Walter De Gruyter',\n",
       " 'Walter Foster Publishing',\n",
       " 'Warner Books',\n",
       " 'Wasendorf & Associates',\n",
       " 'Washington Square Press',\n",
       " 'Watkins',\n",
       " 'Watson-Guptill',\n",
       " \"Webster'S New World\",\n",
       " 'Weidenfeld & Nicolson',\n",
       " 'White Wolf Games Studio',\n",
       " 'Wildstorm',\n",
       " 'Wiley',\n",
       " 'Wilhelm Goldmann Gmbh',\n",
       " 'William Heinemann',\n",
       " 'William Morrow',\n",
       " 'William Morrow Paperbacks',\n",
       " 'Windsor Golden Series',\n",
       " 'Wings',\n",
       " 'Wipf & Stock',\n",
       " 'Wizards Of The Coast',\n",
       " 'Wordsworth Editions',\n",
       " 'Wyatt Book',\n",
       " 'Xlibris Corporation',\n",
       " 'Y Lolfa',\n",
       " 'Yale University Press',\n",
       " 'Yapı Kredi Yayınları',\n",
       " 'Yearling',\n",
       " 'Yoruba Theological Archministry',\n",
       " 'Yosemite Conservancy',\n",
       " 'Your Coach Digital',\n",
       " 'Zebra',\n",
       " 'Zondervan',\n",
       " 'Éditions 10/18',\n",
       " 'Éditions De Minuit',\n",
       " 'Éditions Du Rocher',\n",
       " 'Эксмо',\n",
       " 'ガンガンコミックス',\n",
       " 'ビブロス',\n",
       " '小学館',\n",
       " '小学館 [ShōGakukan]',\n",
       " '時報出版',\n",
       " '東立',\n",
       " '皇冠文化出版有限公司',\n",
       " '聯經出版事業股份有限公司',\n",
       " '英文漢聲出版股份有限公司',\n",
       " '角川書店',\n",
       " '講談社',\n",
       " '集英社']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['publisher'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84168f34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, I go through the list and do the thing I was avoiding up till now, individually correcting/mapping publishers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "29eebbc9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "publisher_mapping = {\n",
    "    '18-Oct': 'Vintage',\n",
    "    'Chatto Windus': 'Chatto & Windus',\n",
    "    'Debols!Llo': 'Debolsillo',\n",
    "    'Douglas Mcintyre': 'Douglas & Mcintyre',\n",
    "    'Doubleday Canada': 'Doubleday Publishing',\n",
    "    'Doubleday': 'Doubleday Publishing',\n",
    "    'Dk': 'Dk Publishing',\n",
    "    'Dk Children': 'Dk Publishing',\n",
    "    'Emecé Editores': 'Emece Editores',\n",
    "    'Faber & Faber Limited': 'Faber & Faber',\n",
    "    'Faber Faber': 'Faber & Faber',\n",
    "    'Fawcett Coventry': 'Fawcett',\n",
    "    'Fawcett Crest': 'Fawcett',\n",
    "    'Fasa Corp.': 'Fasa Corporation',\n",
    "    'Five Star': 'Five Star Trade',\n",
    "    'Fourth Estate Paperbacks': 'Fourth Estate',\n",
    "    'Hill & Wang Publ.': 'Hill & Wang',\n",
    "    'Hodder & Stoughton Educational Division': 'Hodder & Stoughton',\n",
    "    'Inner Traditions International': 'Inner Traditions',\n",
    "    'Insel Frankfurt': 'Insel',\n",
    "    'John Wiley': 'John Wiley & Sons',\n",
    "    'Limelight Editions': 'Limelight',\n",
    "    'Liveright': 'Liveright Publishing Corp.',\n",
    "    'Nal': 'New American Library',\n",
    "    'Nal Jam': 'New American Library',\n",
    "    'Nal Trade': 'New American Library',\n",
    "    'National Geographic Society': 'National Geographic',\n",
    "    'Plaza & Janes Editores Sa': 'Plaza & Janés',\n",
    "    'Plaza & Janés Mexico': 'Plaza & Janés',\n",
    "    'Plaza Y Janés': 'Plaza & Janés',\n",
    "    'Prentice Hall Ptr': 'Prentice Hall',\n",
    "    'Roc Hardcover': 'Roc',\n",
    "    'Roc Trade': 'Roc',\n",
    "    'Rowohlt Taschenbuch Gmbh': 'Rowohlt',\n",
    "    'Schirmer Mosel': 'Schirmer/Mosel',\n",
    "    'Simon Schuster': 'Simon & Schuster',\n",
    "    'Thames Hudson': 'Thames & Hudson',\n",
    "    'Ullstein Buchverlage Gmbh & Co. Kg / Ullstein Tas': 'Ullstein',\n",
    "    'Virago Uk': 'Virago',\n",
    "    'Vision Forum': 'Vision',\n",
    "    'W. W. Norton Company': 'W. W. Norton & Company',\n",
    "    'William Morrow Paperbacks': 'William Morrow',\n",
    "    '小学館 [ShōGakukan]': '小学館'\n",
    "}\n",
    "\n",
    "df['publisher'] = df['publisher'].replace(publisher_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "391cff62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['publisher'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "246a4af8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>isbn_10</th>\n",
       "      <th>isbn_13</th>\n",
       "      <th>language_code</th>\n",
       "      <th>audio_book</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>J.K. Rowling/Mary GrandPré</td>\n",
       "      <td>0439785960</td>\n",
       "      <td>9780439785969</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>652</td>\n",
       "      <td>2095690</td>\n",
       "      <td>4.57</td>\n",
       "      <td>27591</td>\n",
       "      <td>2006-09-16</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>J.K. Rowling/Mary GrandPré</td>\n",
       "      <td>0439358078</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>870</td>\n",
       "      <td>2153167</td>\n",
       "      <td>4.49</td>\n",
       "      <td>29221</td>\n",
       "      <td>2004-09-01</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (Harry...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>0439554896</td>\n",
       "      <td>9780439554893</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>352</td>\n",
       "      <td>6333</td>\n",
       "      <td>4.42</td>\n",
       "      <td>244</td>\n",
       "      <td>2003-11-01</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Harr...</td>\n",
       "      <td>J.K. Rowling/Mary GrandPré</td>\n",
       "      <td>043965548X</td>\n",
       "      <td>9780439655484</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>435</td>\n",
       "      <td>2339585</td>\n",
       "      <td>4.56</td>\n",
       "      <td>36325</td>\n",
       "      <td>2004-05-01</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Harry Potter Boxed Set Books 1-5 (Harry Potter...</td>\n",
       "      <td>J.K. Rowling/Mary GrandPré</td>\n",
       "      <td>0439682584</td>\n",
       "      <td>9780439682589</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>2690</td>\n",
       "      <td>41428</td>\n",
       "      <td>4.78</td>\n",
       "      <td>164</td>\n",
       "      <td>2004-09-13</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title  \\\n",
       "0        1  Harry Potter and the Half-Blood Prince (Harry ...   \n",
       "1        2  Harry Potter and the Order of the Phoenix (Har...   \n",
       "2        3  Harry Potter and the Chamber of Secrets (Harry...   \n",
       "3        4  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
       "4        5  Harry Potter Boxed Set Books 1-5 (Harry Potter...   \n",
       "\n",
       "                      authors     isbn_10        isbn_13 language_code  \\\n",
       "0  J.K. Rowling/Mary GrandPré  0439785960  9780439785969           eng   \n",
       "1  J.K. Rowling/Mary GrandPré  0439358078  9780439358071           eng   \n",
       "2                J.K. Rowling  0439554896  9780439554893           eng   \n",
       "3  J.K. Rowling/Mary GrandPré  043965548X  9780439655484           eng   \n",
       "4  J.K. Rowling/Mary GrandPré  0439682584  9780439682589           eng   \n",
       "\n",
       "   audio_book  num_pages  ratings_count  average_rating  text_reviews_count  \\\n",
       "0       False        652        2095690            4.57               27591   \n",
       "1       False        870        2153167            4.49               29221   \n",
       "2       False        352           6333            4.42                 244   \n",
       "3       False        435        2339585            4.56               36325   \n",
       "4       False       2690          41428            4.78                 164   \n",
       "\n",
       "  publication_date   publisher  \n",
       "0       2006-09-16  Scholastic  \n",
       "1       2004-09-01  Scholastic  \n",
       "2       2003-11-01  Scholastic  \n",
       "3       2004-05-01  Scholastic  \n",
       "4       2004-09-13  Scholastic  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True)\n",
    "df['book_id'] = df.index + 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5b84d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Author and Publication Tables\n",
    "\n",
    "Now that I've cleaned up the publishers, I'm ready to create seperate tables. I will be making both an `author` and a `publisher` table. The `author` table is necessary in order to properly extract names from the `authors` column of the our original dataset, without creating a lot of extra null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "43228abc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A. Bartlett Giamatti</td>\n",
       "      <td>8140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A. Elizabeth Delany</td>\n",
       "      <td>4761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A. Merritt</td>\n",
       "      <td>6263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A. Roger Merrill</td>\n",
       "      <td>9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A. Walton Litz</td>\n",
       "      <td>6190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A.B. Yehoshua</td>\n",
       "      <td>7173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>A.B. Yehoshua</td>\n",
       "      <td>8041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A.D.P. Briggs</td>\n",
       "      <td>4955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A.E. Cunningham</td>\n",
       "      <td>10115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A.E. van Vogt</td>\n",
       "      <td>10117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>A.G. Pasquella</td>\n",
       "      <td>10657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>A.H. Armstrong</td>\n",
       "      <td>6958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>A.J. Arberry</td>\n",
       "      <td>9880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>A.J. Ayer</td>\n",
       "      <td>6184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>A.J. Ayer</td>\n",
       "      <td>6185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>A.J. Jacobs</td>\n",
       "      <td>7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>A.J. McAllister</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>A.M. Dellamonica</td>\n",
       "      <td>9704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>A.M. Homes</td>\n",
       "      <td>7640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>A.N. Roquelaure</td>\n",
       "      <td>5175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18</td>\n",
       "      <td>A.N. Roquelaure</td>\n",
       "      <td>7010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18</td>\n",
       "      <td>A.N. Roquelaure</td>\n",
       "      <td>6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18</td>\n",
       "      <td>A.N. Roquelaure</td>\n",
       "      <td>7011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19</td>\n",
       "      <td>A.N. Wilson</td>\n",
       "      <td>8682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19</td>\n",
       "      <td>A.N. Wilson</td>\n",
       "      <td>5040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>A.R. Braunmuller</td>\n",
       "      <td>10594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>A.R. Braunmuller</td>\n",
       "      <td>4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>A.R. Braunmuller</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>A.R. Braunmuller</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21</td>\n",
       "      <td>A.R. Taylor</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    author_id           author_name  book_id\n",
       "0           1  A. Bartlett Giamatti     8140\n",
       "1           2   A. Elizabeth Delany     4761\n",
       "2           3            A. Merritt     6263\n",
       "3           4      A. Roger Merrill     9220\n",
       "4           5        A. Walton Litz     6190\n",
       "5           6         A.B. Yehoshua     7173\n",
       "6           6         A.B. Yehoshua     8041\n",
       "7           7         A.D.P. Briggs     4955\n",
       "8           8       A.E. Cunningham    10115\n",
       "9           9         A.E. van Vogt    10117\n",
       "10         10        A.G. Pasquella    10657\n",
       "11         11        A.H. Armstrong     6958\n",
       "12         12          A.J. Arberry     9880\n",
       "13         13             A.J. Ayer     6184\n",
       "14         13             A.J. Ayer     6185\n",
       "15         14           A.J. Jacobs     7304\n",
       "16         15       A.J. McAllister      145\n",
       "17         16      A.M. Dellamonica     9704\n",
       "18         17            A.M. Homes     7640\n",
       "19         18       A.N. Roquelaure     5175\n",
       "20         18       A.N. Roquelaure     7010\n",
       "21         18       A.N. Roquelaure     6720\n",
       "22         18       A.N. Roquelaure     7011\n",
       "23         19           A.N. Wilson     8682\n",
       "24         19           A.N. Wilson     5040\n",
       "25         20      A.R. Braunmuller    10594\n",
       "26         20      A.R. Braunmuller     4041\n",
       "27         20      A.R. Braunmuller      432\n",
       "28         20      A.R. Braunmuller      421\n",
       "29         21           A.R. Taylor      730"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split authors column and create a new dataframe\n",
    "authors_df = df[['book_id', 'authors']].set_index('book_id').stack().str.split('/', expand=True).stack().reset_index(level=1, drop=True).reset_index(name='author_name')\n",
    "\n",
    "# Create author_id column\n",
    "unique_authors = sorted(authors_df['author_name'].unique())\n",
    "author_id = range(1, len(unique_authors) + 1)\n",
    "authors_dict = {'author_name': unique_authors, 'author_id': author_id}\n",
    "authors_id_df = pd.DataFrame(authors_dict)\n",
    "\n",
    "authors_df = pd.merge(authors_df, authors_id_df, on='author_name')\n",
    "\n",
    "# Reorder columns and rows\n",
    "authors_df = authors_df[['author_id', 'author_name', 'book_id']]\n",
    "authors_df = authors_df.sort_values(by='author_id')\n",
    "authors_df = authors_df.reset_index(drop=True)\n",
    "authors_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Looks good! Now for the publishers. The `publication` table needs to be created in order for me to more easily implement my upload to neo4j. It will be pretty straight forward, with `publisher_id`, `publisher_name`, `publication_date`, and `book_id` foreign key. The only thing that really needs to be created is the `publisher_id`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53c22c73",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10/18</td>\n",
       "      <td>2001-02-15</td>\n",
       "      <td>6904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10/18</td>\n",
       "      <td>1998-11-18</td>\n",
       "      <td>7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1St Book Library</td>\n",
       "      <td>2003-01-14</td>\n",
       "      <td>8093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aa World Services</td>\n",
       "      <td>2002-02-10</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abacus</td>\n",
       "      <td>1997-03-03</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Abacus</td>\n",
       "      <td>2005-01-20</td>\n",
       "      <td>8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Abacus</td>\n",
       "      <td>2004-02-05</td>\n",
       "      <td>8656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Abacus</td>\n",
       "      <td>1989-02-01</td>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Abacus</td>\n",
       "      <td>1995-11-12</td>\n",
       "      <td>10583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Abacus</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Abstract Studio</td>\n",
       "      <td>2005-12-14</td>\n",
       "      <td>4359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Academy Chicago</td>\n",
       "      <td>2005-08-30</td>\n",
       "      <td>6297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>1987-06-15</td>\n",
       "      <td>10123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2005-10-04</td>\n",
       "      <td>10219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2003-01-28</td>\n",
       "      <td>5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2007-08-07</td>\n",
       "      <td>5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>1989-12-01</td>\n",
       "      <td>5636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>1988-04-01</td>\n",
       "      <td>5635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2006-11-07</td>\n",
       "      <td>5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>5493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2007-03-06</td>\n",
       "      <td>5492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>1985-02-01</td>\n",
       "      <td>10224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2006-08-01</td>\n",
       "      <td>5765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>10609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2006-06-06</td>\n",
       "      <td>5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2001-11-01</td>\n",
       "      <td>5768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>1998-10-01</td>\n",
       "      <td>5769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2006-03-07</td>\n",
       "      <td>5899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>7736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>Ace</td>\n",
       "      <td>1987-07-15</td>\n",
       "      <td>7785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    publisher_id     publisher_name publication_date  book_id\n",
       "0              1              10/18       2001-02-15     6904\n",
       "1              1              10/18       1998-11-18     7329\n",
       "2              2   1St Book Library       2003-01-14     8093\n",
       "3              3  Aa World Services       2002-02-10      926\n",
       "4              4             Abacus       1997-03-03     2069\n",
       "5              4             Abacus       2005-01-20     8768\n",
       "6              4             Abacus       2004-02-05     8656\n",
       "7              4             Abacus       1989-02-01     1756\n",
       "8              4             Abacus       1995-11-12    10583\n",
       "9              4             Abacus       2000-04-01     1897\n",
       "10             5    Abstract Studio       2005-12-14     4359\n",
       "11             6    Academy Chicago       2005-08-30     6297\n",
       "12             7                Ace       1987-06-15    10123\n",
       "13             7                Ace       2005-10-04    10219\n",
       "14             7                Ace       2003-01-28     5093\n",
       "15             7                Ace       2007-08-07     5764\n",
       "16             7                Ace       1989-12-01     5636\n",
       "17             7                Ace       1988-04-01     5635\n",
       "18             7                Ace       2006-11-07     5491\n",
       "19             7                Ace       2007-01-02     5493\n",
       "20             7                Ace       2007-03-06     5492\n",
       "21             7                Ace       1985-02-01    10224\n",
       "22             7                Ace       2006-08-01     5765\n",
       "23             7                Ace       2013-06-04    10609\n",
       "24             7                Ace       2006-06-06     5494\n",
       "25             7                Ace       2001-11-01     5768\n",
       "26             7                Ace       1998-10-01     5769\n",
       "27             7                Ace       2006-03-07     5899\n",
       "28             7                Ace       2006-11-01     7736\n",
       "29             7                Ace       1987-07-15     7785"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create publisher ids\n",
    "unique_publishers = sorted(df['publisher'].unique())\n",
    "publisher_id = range(1, len(unique_publishers) + 1)\n",
    "publisher_dict = {'publisher_id': publisher_id, 'publisher': unique_publishers}\n",
    "unique_publisher_df = pd.DataFrame(publisher_dict)\n",
    "\n",
    "# create new table\n",
    "publisher_df = df[['publisher', 'publication_date', 'book_id']]\n",
    "publisher_df = pd.merge(publisher_df, unique_publisher_df, on='publisher')\n",
    "\n",
    "# resturcture table\n",
    "publisher_df = publisher_df[['publisher_id', 'publisher', 'publication_date', 'book_id']]\n",
    "publisher_df = publisher_df.sort_values(by='publisher_id')\n",
    "publisher_df = publisher_df.reset_index(drop=True)\n",
    "publisher_df = publisher_df.rename(columns={'publisher': 'publisher_name'})\n",
    "publisher_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3cb704",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Wrapping up!\n",
    "\n",
    "The final steps are removing redundant columns from my original dataframe and using `.to_csv` to export all my new tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4c0c213d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>isbn_10</th>\n",
       "      <th>isbn_13</th>\n",
       "      <th>language_code</th>\n",
       "      <th>audio_book</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>0439785960</td>\n",
       "      <td>9780439785969</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>652</td>\n",
       "      <td>2095690</td>\n",
       "      <td>4.57</td>\n",
       "      <td>27591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>0439358078</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>870</td>\n",
       "      <td>2153167</td>\n",
       "      <td>4.49</td>\n",
       "      <td>29221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (Harry...</td>\n",
       "      <td>0439554896</td>\n",
       "      <td>9780439554893</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>352</td>\n",
       "      <td>6333</td>\n",
       "      <td>4.42</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Harr...</td>\n",
       "      <td>043965548X</td>\n",
       "      <td>9780439655484</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>435</td>\n",
       "      <td>2339585</td>\n",
       "      <td>4.56</td>\n",
       "      <td>36325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Harry Potter Boxed Set Books 1-5 (Harry Potter...</td>\n",
       "      <td>0439682584</td>\n",
       "      <td>9780439682589</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>2690</td>\n",
       "      <td>41428</td>\n",
       "      <td>4.78</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title     isbn_10  \\\n",
       "0        1  Harry Potter and the Half-Blood Prince (Harry ...  0439785960   \n",
       "1        2  Harry Potter and the Order of the Phoenix (Har...  0439358078   \n",
       "2        3  Harry Potter and the Chamber of Secrets (Harry...  0439554896   \n",
       "3        4  Harry Potter and the Prisoner of Azkaban (Harr...  043965548X   \n",
       "4        5  Harry Potter Boxed Set Books 1-5 (Harry Potter...  0439682584   \n",
       "\n",
       "         isbn_13 language_code  audio_book  num_pages  ratings_count  \\\n",
       "0  9780439785969           eng       False        652        2095690   \n",
       "1  9780439358071           eng       False        870        2153167   \n",
       "2  9780439554893           eng       False        352           6333   \n",
       "3  9780439655484           eng       False        435        2339585   \n",
       "4  9780439682589           eng       False       2690          41428   \n",
       "\n",
       "   average_rating  text_reviews_count  \n",
       "0            4.57               27591  \n",
       "1            4.49               29221  \n",
       "2            4.42                 244  \n",
       "3            4.56               36325  \n",
       "4            4.78                 164  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['authors', 'publication_date', 'publisher'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a8aba4a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/books_cleaned.csv', index=False)\n",
    "authors_df.to_csv('data/authors.csv')\n",
    "publisher_df.to_csv('data/publishers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dd1021",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# See neo4j_upload.ipynb for next steps!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}